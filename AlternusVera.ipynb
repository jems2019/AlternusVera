{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternus Vera \n",
    "\n",
    " \n",
    "\n",
    "-----\n",
    "\n",
    "GitHub URL: \n",
    "\n",
    "\n",
    "### Liar Liar Pants on Fire Dataset Description \n",
    "- It has 3 files test, training and valid.\n",
    "- Each file has 14 columns\n",
    "    \n",
    "    Column 1: the ID of the statement ([ID].json).\n",
    "    \n",
    "    Column 2: the label.\n",
    "    \n",
    "    Column 3: the statement.\n",
    "    \n",
    "    Column 4: the subject(s).\n",
    "    \n",
    "    Column 5: the speaker.\n",
    "    \n",
    "    Column 6: the speaker's job title.\n",
    "    \n",
    "    Column 7: the state info.\n",
    "    \n",
    "    Column 8: the party affiliation.\n",
    "    \n",
    "    Column 9-13: the total credit history count, including the current statement.\n",
    "    \n",
    "    Column 14: the context (venue / location of the speech or statement).\n",
    "\n",
    "### Process \n",
    "- Load the Data\n",
    "- Distillation Process\n",
    "    - Data Cleaning and Text Preprocessing\n",
    "    - Visualization\n",
    "- **Feature 1 :** Sentiment Analysis \n",
    "- **Feature 2 :** LDA Topic Modelling\n",
    "- **Feature 3 :** Sensationalism \n",
    "- **Feature 4 :** Political Affiliation \n",
    "- **Feature 5 :** Clickbait \n",
    "- **Feature 6 :** Spam \n",
    "- **Feature 7 :** Author Credibility \n",
    "- **Feature 8 :** Source Reputation\n",
    "- **Feature 9 :** Content Length     \n",
    "- **Feature 10 :** Word Frequency \n",
    "- Vector Classification Modeling \n",
    "- Ranking and Importance\n",
    "- Merge all features and individual contributions\n",
    "- Form Polynomial Equation \n",
    "    \n",
    "\n",
    "### Feature Selection\n",
    "**List top Features Selected based on research articles**\n",
    "\n",
    "\n",
    "\n",
    "### Team Contributions example:\n",
    "\n",
    "|Features  |  Member |\n",
    "|-----|-----|\n",
    "| Feature name(s)                         |  Member name(s) |  \n",
    "| Feature name(s)                 |  Member name(s) | \n",
    "| Feature name(s)                   |  Member name(s)  |   \n",
    "| Feature name(s)                             |  Member name(s) |\n",
    "\n",
    " \n",
    "#### Enrichment Dataset Details\n",
    "\n",
    "- SenticNet5 sensational words corpus\n",
    "- Google News 3million words corpus for spell check\n",
    "- Sensational Words Dictionary \n",
    "- PoliticalFact Fake news and Real News Content \n",
    "- Clickbait and non_clickbait datasets\n",
    "- Spam Dictionary \n",
    "\n",
    "#### Libraries Used \n",
    "\n",
    "- NLTK \n",
    "- Gensim \n",
    "- Numpy\n",
    "- Pandas\n",
    "- CSV\n",
    "- WordCloud\n",
    "- Seaborn\n",
    "- Scipy\n",
    "- Regualr Expression\n",
    "- Matplotlib\n",
    "- Sklearn \n",
    "\n",
    "\n",
    "#### What did I try and What worked? \n",
    "\n",
    "> Explain your work ...\n",
    "\n",
    "#### What did not work?\n",
    "\n",
    "> Explain your work ...\n",
    "\n",
    "\n",
    "#### What alternatives did you try?\n",
    "\n",
    "> Explain your work \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sramini/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/sramini/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package punkt to /Users/sramini/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/sramini/nltk_data...\n",
      "[nltk_data] Downloading package wordnet to /Users/sramini/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import gensim\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('wordnet')\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import sparse\n",
    "# Code source: https://degravek.github.io/project-pages/project1/2017/04/28/New-Notebook/\n",
    "# Dataset from Chakraborty et al. (https://github.com/bhargaviparanjape/clickbait/tree/master/dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the test, training and valid data from files\n",
    "# Header = 0 indicates that the first line of the file contains column names,\n",
    "# As there is no Header, create a column names for each column in the dataset\n",
    "# delimiter = \\t indicates that the fields are seperated by tabs, and \n",
    "\n",
    "\n",
    "test_filename = 'input_data/dataset/test.tsv'\n",
    "train_filename = 'input_data/dataset/train.tsv'\n",
    "valid_filename = 'input_data/dataset/valid.tsv'\n",
    "\n",
    "colnames = ['jsonid', 'label', 'headline_text', 'subject', 'speaker', 'speakerjobtitle', 'stateinfo','partyaffiliation', 'barelytruecounts', 'falsecounts','halftruecounts','mostlytrueocunts','pantsonfirecounts','context']\n",
    "\n",
    "train_news = pd.read_csv(train_filename, sep='\\t', names = colnames, error_bad_lines=False)\n",
    "test_news = pd.read_csv(test_filename, sep='\\t', names = colnames, error_bad_lines=False)\n",
    "valid_news = pd.read_csv(valid_filename, sep='\\t', names = colnames, error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dim: (10240, 14) test dim: (1267, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jsonid</th>\n",
       "      <th>label</th>\n",
       "      <th>headline_text</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speakerjobtitle</th>\n",
       "      <th>stateinfo</th>\n",
       "      <th>partyaffiliation</th>\n",
       "      <th>barelytruecounts</th>\n",
       "      <th>falsecounts</th>\n",
       "      <th>halftruecounts</th>\n",
       "      <th>mostlytrueocunts</th>\n",
       "      <th>pantsonfirecounts</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2635.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>dwayne-bohac</td>\n",
       "      <td>State representative</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a mailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10540.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>energy,history,job-accomplishments</td>\n",
       "      <td>scott-surovell</td>\n",
       "      <td>State delegate</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a floor speech.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       jsonid      label                                      headline_text  \\\n",
       "0   2635.json      false  Says the Annies List political group supports ...   \n",
       "1  10540.json  half-true  When did the decline of coal start? It started...   \n",
       "\n",
       "                              subject         speaker       speakerjobtitle  \\\n",
       "0                            abortion    dwayne-bohac  State representative   \n",
       "1  energy,history,job-accomplishments  scott-surovell        State delegate   \n",
       "\n",
       "  stateinfo partyaffiliation  barelytruecounts  falsecounts  halftruecounts  \\\n",
       "0     Texas       republican               0.0          1.0             0.0   \n",
       "1  Virginia         democrat               0.0          0.0             1.0   \n",
       "\n",
       "   mostlytrueocunts  pantsonfirecounts          context  \n",
       "0               0.0                0.0         a mailer  \n",
       "1               1.0                0.0  a floor speech.  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display check the dimensions and the first 2 rows of the file.\n",
    "\n",
    "print('train dim:',train_news.shape, 'test dim:', test_news.shape)\n",
    "train_news.iloc[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Text Preprocessing \n",
    "\n",
    "*Steps included in the preprocessing:*\n",
    "- Remove Special Characters and Punctuations\n",
    "- Lower case the news\n",
    "- Tokenization\n",
    "- Remove Stop Words\n",
    "- Lemmatization\n",
    "- Stemming \n",
    "- Spell Check "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Putting It All Together \n",
    "\n",
    "To make the code reusable, we need to create a function that can be called many times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def cleaning(raw_news):\n",
    "    import nltk\n",
    "    \n",
    "    # 1. Remove non-letters/Special Characters and Punctuations\n",
    "    news = re.sub(\"[^a-zA-Z]\", \" \", raw_news)\n",
    "    \n",
    "    # 2. Convert to lower case.\n",
    "    news =  news.lower()\n",
    "    \n",
    "    # 3. Tokenize.\n",
    "    news_words = nltk.word_tokenize( news)\n",
    "    \n",
    "    # 4. Convert the stopwords list to \"set\" data type.\n",
    "    stops = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "    \n",
    "    # 5. Remove stop words. \n",
    "    words = [w for w in  news_words  if not w in stops]\n",
    "    \n",
    "    # 6. Lemmentize \n",
    "    wordnet_lem = [ WordNetLemmatizer().lemmatize(w) for w in words ]\n",
    "    \n",
    "    # 7. Stemming\n",
    "    stems = [nltk.stem.SnowballStemmer('english').stem(w) for w in wordnet_lem ]\n",
    "    \n",
    "    # 8. Join the stemmed words back into one string separated by space, and return the result.\n",
    "    return \" \".join(stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time to clean, tokenize and stem train data: \n",
      " 10240 news: 0.24684985081354777 min\n",
      "\n",
      "\n",
      "Time to clean, tokenize and stem test data: \n",
      " 1267 news: 0.027518534660339357 min\n",
      "\n",
      "\n",
      "Time to clean, tokenize and stem valid data: \n",
      " 1284 news: 0.018344418207804362 min\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# clean training and test data \n",
    "# create new column \"tokenized\"\n",
    "t1 = time.time()\n",
    "\n",
    "# Add the processed data to the original data. \n",
    "# Perhaps using apply function would be more elegant and concise than using for loop\n",
    "train_news['clean'] = train_news[\"headline_text\"].apply(cleaning) \n",
    "\n",
    "t2 = time.time()\n",
    "print(\"\\nTime to clean, tokenize and stem train data: \\n\", len(train_news), \"news:\", (t2-t1)/60, \"min\")\n",
    "\n",
    "t1 = time.time()\n",
    "test_news['clean'] = test_news[\"headline_text\"].apply(cleaning)\n",
    "\n",
    "t2 = time.time()\n",
    "print(\"\\n\\nTime to clean, tokenize and stem test data: \\n\", len(test_news), \"news:\", (t2-t1)/60, \"min\")\n",
    "\n",
    "t1 = time.time()\n",
    "valid_news['clean'] = valid_news[\"headline_text\"].apply(cleaning)\n",
    "\n",
    "t2 = time.time()\n",
    "print(\"\\n\\nTime to clean, tokenize and stem valid data: \\n\", len(valid_news), \"news:\", (t2-t1)/60, \"min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Google News corpus word2vec](http://mccormickml.com/2016/04/12/googles-pretrained-word2vec-model-in-python/)\n",
    "\n",
    "### Spell Check \n",
    "\n",
    "-  You can download the pre-trained model [**here**](https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit)\n",
    "\n",
    "- Or clone it from GitHub [**GoogleNews-vectors-negative300**](https://github.com/mmihaltz/word2vec-GoogleNews-vectors)\n",
    "\n",
    "> It’s 1.5GB! It includes word vectors for a vocabulary of 3 million words and phrases that they trained on roughly 100 billion words from a Google News dataset. The vector length is 300 features.\n",
    "\n",
    "**3 million words * 300 features * 4bytes/feature = ~3.35GB**\n",
    "\n",
    "> This file consist of the word2vec -  pre-trained Google News corpus (3 billion running words) to word vector model (3 million 300-dimension English word vectors).\n",
    "\n",
    "> Look at the [**vocabulory list**](https://github.com/chrisjmccormick/inspect_word2vec/tree/master/vocabulary) used to train this model. Each text file contains 100,000 entries from the model. \n",
    "\n",
    "\n",
    ">  There are few things that this dataset contains and not. It has stop words like  “the”, “also”, “should” and does not have stop words like “a”, “and”, “of”. As I have removed the stop words the complexity is reduced as there is no need to check the spelling for stop words. \n",
    "\n",
    "> It does have numbers but in the form of entried wiht #. e.g., you won’t find “100”. But it does include entries like “###MHz_DDR2_SDRAM”. \n",
    "\n",
    "The model used [**WinPython-64bit-2.7.10.3**](https://winpython.github.io/) for efficient python distribution on Windows system. Helps to run the scripts in batches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'input_data/GoogleNews-vectors-negative300.bin.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-2fd59537c2fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input_data/GoogleNews-vectors-negative300.bin.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex2word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mw_rank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m   1474\u001b[0m         return _load_word2vec_format(\n\u001b[1;32m   1475\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1476\u001b[0;31m             limit=limit, datatype=datatype)\n\u001b[0m\u001b[1;32m   1477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_keras_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/gensim/models/utils_any2vec.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading projection weights from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmart_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# throws for invalid file format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36msmart_open\u001b[0;34m(uri, mode, **kw)\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0mtransport_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_ext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_extension\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransport_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransport_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mscrubbed_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, transport_params)\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0mbinary_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m     \u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_binary_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransport_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mignore_ext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mdecompressed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m_open_binary_stream\u001b[0;34m(uri, mode, transport_params)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheme\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"file\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mfobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheme\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msmart_open_ssh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSCHEMES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'input_data/GoogleNews-vectors-negative300.bin.gz'"
     ]
    }
   ],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('input_data/GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "words = model.index2word\n",
    "\n",
    "w_rank = {}\n",
    "for i,word in enumerate(words):\n",
    "    w_rank[word] = i\n",
    "\n",
    "WORDS = w_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return - WORDS.get(word, 0)\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spell_checker(text):\n",
    "    all_words = re.findall(r'\\w+', text.lower()) # split sentence to words\n",
    "    spell_checked_text  = []\n",
    "    for i in range(len(all_words)):\n",
    "        spell_checked_text.append(correction(all_words[i]))\n",
    "    return ' '.join(spell_checked_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before: \\n\", train_news['clean'][0] )\n",
    "t1 = time.time()\n",
    "train_news['clean'] = train_news['clean'].apply(spell_checker)\n",
    "t2 = time.time()\n",
    "print(\"\\nTime to spell check the train data: \\nn\", len(train_news), \"news:\", (t2-t1)/60, \"min\")\n",
    "\n",
    "print(\"\\nAfter: \\n\",train_news['clean'][0] )\n",
    "train_news.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "test_news['clean'] = test_news['clean'].apply(spell_checker)\n",
    "test_news.head(5)\n",
    "t2 = time.time()\n",
    "print(\"\\nTime to spell check the test data: \\n\", len(test_news), \"news:\", (t2-t1)/60, \"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "valid_news['clean'] = valid_news['clean'].apply(spell_checker)\n",
    "valid_news.head(5)\n",
    "t2 = time.time()\n",
    "print(\"\\nTime to spell check the valid data: \\n\", len(valid_news), \"news:\", (t2-t1)/60, \"min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saved the trained dataset into a seperate CSV file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_news.to_csv(\"input_data/train_processed.csv\", sep=',')\n",
    "test_news.to_csv(\"input_data/test_processed.csv\", sep=',')\n",
    "valid_news.to_csv(\"input_data/valid_processed.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization \n",
    "\n",
    "#### WordCloud \n",
    "\n",
    "> As a tool for visualization by using the frequency of words appeared in text, we use WordCloud. Note that it can give more information and insight of texts by analyzing correlations and similarities between words rather than analyzing texts only by the frequency of words appeared; however, it can give you some general shape of what this text is about quickly and intuitively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cloud(data,backgroundcolor = 'white', width = 800, height = 600):\n",
    "    wordcloud = WordCloud(stopwords = STOPWORDS, background_color = backgroundcolor,\n",
    "                         width = width, height = height).generate(data)\n",
    "    plt.figure(figsize = (15, 10))\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "cloud(' '.join(train_news['clean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud(' '.join(test_news['clean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud(' '.join(valid_news['clean']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inferences from visulaization: \n",
    "- The large words are the words that are frequently appeared in the text/corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Feature 1: Sentiment analysis \n",
    "\n",
    "#### Using Vader Sentiment Analyser\n",
    "\n",
    "##### [Sentiment Intensity Analyzer](http://t-redactyl.io/blog/2017/04/using-vader-to-handle-sentiment-analysis-with-social-media-text.html)\n",
    "\n",
    "\n",
    "> VADER, or the **Valence Aware Dictionary and sEntiment Reasoner** has created a package that performes sentiment analysis using the polarity-based, where pieces of texts are classified as either positive or negative, or valence-based, where the intensity of the sentiment is taken into account. For example, the words ‘good’ and ‘excellent’ would be treated the same in a polarity-based approach, whereas ‘excellent’ would be treated as more positive than ‘good’ in a valence-based approach\n",
    "\n",
    "- It is based on lexicons of sentiment-related word.\n",
    "- The first three, positive, neutral and negative, represent the proportion of the text that falls into those categories.\n",
    "- The final metric, the compound score, is the sum of all of the lexicon ratings which have been standardised to range between -1 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import nltk.sentiment\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "senti = nltk.sentiment.vader.SentimentIntensityAnalyzer()\n",
    "\n",
    "def print_sentiment_scores(sentence):\n",
    "    snt = senti.polarity_scores(sentence)\n",
    "    print(\"{:-<40} \\n{}\".format(sentence, str(snt)))\n",
    "    \n",
    "print_sentiment_scores(train_news['clean'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vader_polarity(snt):\n",
    "    if not snt:\n",
    "        return None\n",
    "    elif snt['neg'] > snt['pos'] and snt['neg'] > snt['neu']:\n",
    "        return -1\n",
    "    elif snt['pos'] > snt['neg'] and snt['pos'] > snt['neu']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to determine if a text is negative(-1) or postive (1) or neutral (0)\n",
    "def get_polarity_type(sentence):\n",
    "    sentimentVector = []\n",
    "    snt = senti.polarity_scores(sentence)\n",
    "    sentimentVector.append(get_vader_polarity(snt))\n",
    "    sentimentVector.append(snt['neg'])\n",
    "    sentimentVector.append(snt['neu'])\n",
    "    sentimentVector.append(snt['pos'])\n",
    "    sentimentVector.append(snt['compound'])\n",
    "    \n",
    "    print(sentimentVector)\n",
    "    return sentimentVector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- senti.polarity_scores is a dictionary\n",
    "- pos and neg indicates - positive and negative emotions in sentence\n",
    "- we should be interested in compound score which calculates the final effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = []\n",
    "vader_pol = []\n",
    "cmp_score = []\n",
    "for row in train_news['clean']:\n",
    "    get_pols = get_polarity_type(row)\n",
    "    sentiment.append(get_pols[1:])\n",
    "    vader_pol.append(get_pols[0])\n",
    "    cmp_score.append(get_pols[1:][-1]) #last element \n",
    "    \n",
    "train_news['sentiment_vector'] = sentiment\n",
    "train_news['vader_polarity'] = vader_pol\n",
    "train_news['sentiment_score'] = cmp_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_news.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = []\n",
    "vader_pol = []\n",
    "cmp_score = []\n",
    "\n",
    "for row in test_news['clean']:\n",
    "    get_pols = get_polarity_type(row)\n",
    "    sentiment.append(get_pols[1:])\n",
    "    vader_pol.append(get_pols[0])\n",
    "    cmp_score.append(get_pols[1:][-1]) #last element \n",
    "    \n",
    "    \n",
    "test_news['sentiment_vector'] = sentiment\n",
    "test_news['vader_polarity'] = vader_pol\n",
    "test_news['sentiment_score'] = cmp_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_news.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = []\n",
    "vader_pol = []\n",
    "cmp_score = []\n",
    "\n",
    "for row in valid_news['clean']:\n",
    "    get_pols = get_polarity_type(row)\n",
    "    sentiment.append(get_pols[1:])\n",
    "    vader_pol.append(get_pols[0])\n",
    "    cmp_score.append(get_pols[1:][-1]) #last element \n",
    "    \n",
    "    \n",
    "valid_news['sentiment_vector'] = sentiment\n",
    "valid_news['vader_polarity'] = vader_pol\n",
    "valid_news['sentiment_score'] = cmp_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_news.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saved the trained dataset into a seperate CSV file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_news.to_csv(\"input_data/train_sentiment.csv\", sep=',')\n",
    "test_news.to_csv(\"input_data/test_sentiment.csv\", sep=',')\n",
    "valid_news.to_csv(\"input_data/valid_sentiment.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnNames = [\"jsonid\", \"label\", \"headline_text\", \"subject\", \"speaker\", \"speaker_job_title\", \"state_info\", \"party_affiliation\", \"barely_true_counts\", \"false_counts\", \"half_true_counts\", \"mostly_true_counts\", \"pants_on_fire_counts\", \"context\",\"clean\", \"sentiment_vector\",\"vader_polarity\", \"sentiment_score\"]\n",
    "dataTrain = pd.read_csv('input_data/train_sentiment.csv', sep=',', header=None, names = columnNames)\n",
    "dataTrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import  LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.porter import *\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class SentimentAnalysis():\n",
    "\n",
    "    def __init__(self):        \n",
    "\n",
    "        columnNames = [\"jsonid\", \"label\", \"headline_text\", \"subject\", \"speaker\", \"speaker_job_title\", \"state_info\", \"party_affiliation\", \"barely_true_counts\", \"false_counts\", \"half_true_counts\", \"mostly_true_counts\", \"pants_on_fire_counts\", \"context\",\"clean\", \"sentiment_vector\",\"vader_polarity\", \"sentiment_score\"]\n",
    "        dataTrain = pd.read_csv('input_data/train_sentiment.csv', sep=',', header=None, names = columnNames)\n",
    "        dataTest = pd.read_csv('input_data/test_sentiment.csv', sep=',', header=None, names = columnNames)\n",
    "\n",
    "        #dropping columns\n",
    "        columnsToRemove = ['jsonid', 'label', 'subject', 'speaker','speaker_job_title', 'state_info', 'party_affiliation', 'barely_true_counts', 'false_counts', 'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts', 'context', 'sentiment_vector']\n",
    "        dataTrain = dataTrain.drop(columns=columnsToRemove)\n",
    "        dataTest = dataTest.drop(columns=columnsToRemove)\n",
    "        dataTrain = dataTrain.loc[1:] \n",
    "        dataTest = dataTest.loc[1:]\n",
    "    \n",
    "    \n",
    "        tfidfV = TfidfVectorizer(stop_words='english', min_df=5, max_df=30, use_idf=True, smooth_idf=True, token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b')\n",
    "\n",
    "        self.logR_pipeline = Pipeline([\n",
    "                ('LogRCV', tfidfV),\n",
    "                ('LogR_clf',LogisticRegression(solver='liblinear', ))#C=32/100))\n",
    "                ])\n",
    "\n",
    "        self.logR_pipeline.fit(dataTrain['headline_text'],dataTrain['vader_polarity'])\n",
    "        predicted_LogR = self.logR_pipeline.predict(dataTest['headline_text'])\n",
    "        score = metrics.accuracy_score(dataTest['vader_polarity'], predicted_LogR)\n",
    "        print(\"Sentiment Analysis Model Trained - accuracy:   %0.6f\" % score)\n",
    "        \n",
    "\n",
    "    def predict(self, text):\n",
    "        predicted = self.logR_pipeline.predict([text])\n",
    "        predicedProb = self.logR_pipeline.predict_proba([text])[:,1]\n",
    "        return bool(predicted), float(predicedProb)\n",
    "    \n",
    "    \n",
    "sa = SentimentAnalysis()\n",
    "sa.predict(\"Says the Annies List political group supports third-trimester abortions on demand.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SentimentAnalysis = SentimentAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DATAMINERS_getSentimentAnalysisScore(text):  # return between 0 and 1, being 0 = True,  1 = Fake\n",
    "    #print(clickBait.predict(\"Should You bring the money now\"))\n",
    "    binaryValue, probValue = SentimentAnalysis.predict(text)\n",
    "    return (float(probValue))\n",
    "\n",
    "print(DATAMINERS_getSentimentAnalysisScore(\"Says the Annies List political group supports third-trimester abortions on demand.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature 2:  LDA Topic Modelling \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_news['index'] = train_news.index\n",
    "data = train_news\n",
    "train_lda = data[['clean', 'index']]\n",
    "train_lda.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_news['index'] = test_news.index\n",
    "data = test_news\n",
    "test_lda = data[['clean', 'index']]\n",
    "test_lda.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_news['index'] = valid_news.index\n",
    "data = valid_news\n",
    "valid_lda = data[['clean', 'index']]\n",
    "valid_lda.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the clean news into list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = train_lda['clean'].map(lambda doc: doc.split(\" \"))\n",
    "processed_docs[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Dirichlet Allocation (LDA)\n",
    "\n",
    "> It is an example of a probabilistic topic model. Topic models are a great way to automatically explore and structure a large set of documents: they group or cluster documents based on the words that occur in them. As documents on similar topics tend to use a similar sub-vocabulary, the resulting clusters of documents can be interpreted as discussing different 'topics'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_tokens(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if len(token) > 3:\n",
    "            result.append(token)\n",
    "    return result\n",
    "tokenized_docs_local = train_news['clean'].map(get_word_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function to build the dictionary and tokenized docs for given feature\n",
    "\n",
    "Below function does the following\n",
    "* #### Dictionary\n",
    "Returns Dictionary given, dataframe and column name\n",
    "* #### Tokenizeddocs\n",
    "Returns Tokenizeddocs, of the all the words in a text in that column can be used for bow_corpus\n",
    "* #### Dictionary is filtered using Gensim filter_extremes\n",
    "    Filter out tokens that appear in less than 15 documents (absolute number) or more than 0.5 documents (fraction of total corpus size, not absolute number). after the above two steps, keep only the first 100000 most frequent tokens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dictionary_print_words(dataframe,colname):\n",
    "    dictionary_gensim = gensim.corpora.Dictionary(processed_docs)\n",
    "    count = 0\n",
    "    print('######## DICTIONARY Words and occurences ########')\n",
    "    for k, v in dictionary_gensim.iteritems():\n",
    "        print(k, v)\n",
    "        count += 1\n",
    "        if count > 10:\n",
    "            break\n",
    "    dictionary_gensim.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
    "    return dictionary_gensim, tokenized_docs_local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gensim filter_extremes\n",
    "\n",
    "> Filter out tokens that appear less than 15 documents (absolute number) or more than 0.5 documents (fraction of total corpus size, not absolute number). after the above two steps, keep only the first 100000 most frequent tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a function to build bow_corpus from dictionary and tokenized_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bow_corpus_print_sample(dataframe,colname):\n",
    "    dictionary_gensim, tokenized_docs_local = get_dictionary_print_words(dataframe, colname)\n",
    "    bow_corpus_local = [dictionary_gensim.doc2bow(doc) for doc in tokenized_docs_local]\n",
    "    bow_doc_local_0 = bow_corpus_local[0]\n",
    "    print('\\n ######## BOW VECTOR FIRST ITEM ########')\n",
    "    print(bow_doc_local_0)\n",
    "    print('\\n ######## PREVIEW BOW ########')\n",
    "    for i in range(len(bow_doc_local_0)):\n",
    "        print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_local_0[i][0], \n",
    "                                               dictionary_gensim[bow_doc_local_0[i][0]], bow_doc_local_0[i][1]))\n",
    "    return bow_corpus_local, dictionary_gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gensim doc2bow**\n",
    "\n",
    "For each document we create a dictionary reporting how many words and how many times those words appear. Save this to ‘bow_corpus’, then check our selected document earlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a function to build tfidf_corpus from bow_corpus\n",
    "\n",
    "Create tf-idf model object using models.TfidfModel on ‘bow_corpus’ and save it to ‘tfidf’, then apply transformation to the entire corpus and call it ‘corpus_tfidf’. Finally we preview TF-IDF scores for our first document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf_corpus_print_sample(bow_corpus_local):\n",
    "    from gensim import corpora, models\n",
    "    tfidf = models.TfidfModel(bow_corpus_local)\n",
    "    tfidf_corpus_local = tfidf[bow_corpus_local]\n",
    "    print('\\n ######## TFIDF VECTOR FIRST ITEM ########')\n",
    "    \n",
    "    from pprint import pprint\n",
    "    for doc in tfidf_corpus_local:\n",
    "        pprint(doc)\n",
    "        break\n",
    "    return tfidf_corpus_local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a function to run ldamodel and print top 10 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lda_model_print_top_topics(bow_corpusforlda,numtopics,dictionaryforlda):\n",
    "    lda_model = gensim.models.LdaMulticore(bow_corpusforlda, num_topics=numtopics, id2word=dictionaryforlda, passes=2, workers=2)\n",
    "    lda_all_topics=lda_model.show_topics(num_topics=numtopics, num_words=10,formatted=False)\n",
    "    lda_topics_words = [(tp[0], [wd[0] for wd in tp[1]]) for tp in lda_all_topics]\n",
    "\n",
    "    #Below Code Prints Topics and Words\n",
    "    for topic,words in lda_topics_words:\n",
    "        print(str(topic)+ \"::\"+ str(words))\n",
    "    return lda_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a function to run ldamodel and print top 10 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lda_model_topics_topwords_print_top_topics(bow_corpusforlda,numtopics,dictionaryforlda):\n",
    "    lda_model = gensim.models.LdaMulticore(bow_corpusforlda, num_topics=numtopics, id2word=dictionaryforlda, passes=2, workers=2, random_state=1)\n",
    "    lda_all_topics=lda_model.show_topics(num_topics=numtopics, num_words=10,formatted=False)\n",
    "    lda_topics_words = [(tp[0], [wd[0] for wd in tp[1]]) for tp in lda_all_topics]\n",
    "\n",
    "    #Below Code Prints Topics and Words\n",
    "    for topic,words in lda_topics_words:\n",
    "        print(str(topic)+ \"::\"+ str(words))\n",
    "    return lda_model,lda_topics_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a function to enrich data with lda topics, lda topics score, top words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_topic_number_score_label_topwords(text,dictionary_local,lda_model_local,lda_topics_top_words_local):\n",
    "    bow_vector_local = dictionary_local.doc2bow(get_word_tokens(text))\n",
    "    topic_number_local, topic_score_local = sorted(\n",
    "        lda_model_local[bow_vector_local], key=lambda tup: -1*tup[1])[0]\n",
    "    #print (topic_number_local, topic_score_local)\n",
    "    return pd.Series([topic_number_local, topic_score_local,\" \".join(lda_topics_top_words_local[int(topic_number_local)][1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a function that can enrich topic data to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_lda_results_to_dataset(dataframe,topiccolnames,coltoapplylda,colnamedictionary,colnameldamodel, colnameldatopwords):\n",
    "    dataframe[topiccolnames] = dataframe.apply(\n",
    "    lambda row: identify_topic_number_score_label_topwords(\n",
    "        row[coltoapplylda],colnamedictionary,colnameldamodel,\n",
    "        colnameldatopwords), axis=1)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words\n",
    "\n",
    "#### Create a dictionary and tokens\n",
    "\n",
    "> Create a dictionary from ‘processed_docs’ containing the number of times a word appears in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a function to convert text to word tokens from cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus_headline, dictionary_headline = get_bow_corpus_print_sample(train_news,\n",
    "                                                                      'clean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running LDA using Bag of Words\n",
    "Train our lda model using gensim.models.LdaMulticore and save it to ‘lda_model’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_headline, lda_headline_topic_words = get_lda_model_topics_topwords_print_top_topics(\n",
    "    bow_corpus_headline, 10 ,dictionary_headline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate TF-IDF bow_corpus\n",
    "Create tf-idf model object using models.TfidfModel on ‘bow_corpus’ and save it to ‘tfidf’, then apply transformation to the entire corpus and call it ‘corpus_tfidf’. Finally we preview TF-IDF scores for our first document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_corpus_headline = get_tfidf_corpus_print_sample(bow_corpus_headline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running LDA model using Bag of Words\n",
    "Train our lda model using gensim.models.LdaMulticore and save it to ‘lda_model’\n",
    "\n",
    "**GOAL**: To get top ten topics with top words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lda_tfidf_model_headline  = get_lda_model_print_top_topics(tfidf_corpus_headline,10,dictionary_headline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation for LDA \n",
    "![[Explanation of LDA](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1508239587/n4ZpIXl_egq7mq.png)](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1508239587/n4ZpIXl_egq7mq.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semisupervised Labeling\n",
    "Based on train,test and valid data explored the topic scores for sample data and identified below topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semisupervised_topic_labels = ['topic0','topic1','topic2','topic3','topic4','topic5','topic6','topic7','topic8','topic9']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Function to add topicnumber, topicscore, topiclabel, topwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_news = update_lda_results_to_dataset(\n",
    "    test_news,headlinetopiccolnames,'clean',\n",
    "  dictionary_headline,lda_model_headline,lda_headline_topic_words)\n",
    "test_news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_news = update_lda_results_to_dataset(\n",
    "    valid_news,headlinetopiccolnames,'clean',\n",
    "  dictionary_headline,lda_model_headline,lda_headline_topic_words)\n",
    "valid_news.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the LDA Distribution of news against Top 10 Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GOAL 1:** *Each of the N documents will be represented in the LDA model by a vector of length M*\n",
    "**GOAL 2:** *Each of the M topics is represented by a vector of length V*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sb\n",
    "def create_distribution(dataFile):\n",
    "    g = sb.countplot(x='topic_number', data=dataFile, palette='hls')\n",
    "    g.set_xticklabels(g.get_xticklabels(),rotation=90)\n",
    "\n",
    "    return g\n",
    "\n",
    "create_distribution(train_news) # TRAIN Document Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_distribution(test_news)# TEST Document Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_distribution(valid_news)# VALID Document Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saved the latest dataset into a seperate CSV file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_news.to_csv(\"input_data/train_lda.csv\", sep=',')\n",
    "test_news.to_csv(\"input_data/test_lda.csv\", sep=',')\n",
    "valid_news.to_csv(\"input_data/valid_lda.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import  LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.porter import *\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class LDATopicModelling():\n",
    "\n",
    "    def __init__(self):        \n",
    "\n",
    "        columnNames = [\"jsonid\", \"label\", \"headline_text\", \"subject\", \"speaker\", \"speaker_job_title\", \"state_info\", \"party_affiliation\", \"barely_true_counts\", \"false_counts\", \"half_true_counts\", \"mostly_true_counts\", \"pants_on_fire_counts\", \"context\",\"clean\", \"sentiment_vector\",\"vader_polarity\", \"sentiment_score\", \"index\", \"topic_number\", \"lda_score\", \"topic_top_words\"]\n",
    "        dataTrain = pd.read_csv('input_data/train_lda.csv', sep=',', header=None, names = columnNames)\n",
    "        dataTest = pd.read_csv('input_data/test_lda.csv', sep=',', header=None, names = columnNames)\n",
    "\n",
    "        #dropping columns\n",
    "        columnsToRemove = ['jsonid', 'label', 'subject', 'speaker','speaker_job_title', 'state_info', 'party_affiliation', 'barely_true_counts', 'false_counts', 'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts', 'context', 'sentiment_vector', 'sentiment_vector','vader_polarity', 'sentiment_score', 'index']\n",
    "        dataTrain = dataTrain.drop(columns=columnsToRemove)\n",
    "        dataTest = dataTest.drop(columns=columnsToRemove)\n",
    "        dataTrain = dataTrain.loc[1:] \n",
    "        dataTest = dataTest.loc[1:]\n",
    "    \n",
    "    \n",
    "        tfidfV = TfidfVectorizer(stop_words='english', min_df=5, max_df=30, use_idf=True, smooth_idf=True, token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b')\n",
    "\n",
    "        self.logR_pipeline = Pipeline([\n",
    "                ('LogRCV', tfidfV),\n",
    "                ('LogR_clf',LogisticRegression(solver='liblinear', ))#C=32/100))\n",
    "                ])\n",
    "\n",
    "        self.logR_pipeline.fit(dataTrain['headline_text'],dataTrain['topic_number'])\n",
    "        predicted_LogR = self.logR_pipeline.predict(dataTest['headline_text'])\n",
    "        score = metrics.accuracy_score(dataTest['topic_number'], predicted_LogR)\n",
    "        print(\"LDA Topic Model Trained - accuracy:   %0.6f\" % score)\n",
    "        \n",
    "\n",
    "    def predict(self, text):\n",
    "        predicted = self.logR_pipeline.predict([text])\n",
    "        predicedProb = self.logR_pipeline.predict_proba([text])[:,1]\n",
    "        return bool(predicted), float(predicedProb)\n",
    "    \n",
    "    \n",
    "# lda = LDATopicModelling()\n",
    "# lda.predict(\"Says the Annies List political group supports third-trimester abortions on demand.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LDATopicModelling' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4bbae9b23f0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mldaTopicModelling\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLDATopicModelling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'LDATopicModelling' is not defined"
     ]
    }
   ],
   "source": [
    "ldaTopicModelling = LDATopicModelling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ldaTopicModelling' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-dd9dc2ae3a13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATAMINERS_getLDATopicModellingScore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Says the Annies List political group supports third-trimester abortions on demand.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-dd9dc2ae3a13>\u001b[0m in \u001b[0;36mDATAMINERS_getLDATopicModellingScore\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mDATAMINERS_getLDATopicModellingScore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# return between 0 and 1, being 0 = True,  1 = Fake\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#print(clickBait.predict(\"Should You bring the money now\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mbinaryValue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobValue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mldaTopicModelling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ldaTopicModelling' is not defined"
     ]
    }
   ],
   "source": [
    "def DATAMINERS_getLDATopicModellingScore(text):  # return between 0 and 1, being 0 = True,  1 = Fake\n",
    "    #print(clickBait.predict(\"Should You bring the money now\"))\n",
    "    binaryValue, probValue = ldaTopicModelling.predict(text)\n",
    "    return (float(probValue))\n",
    "\n",
    "print(DATAMINERS_getLDATopicModellingScore(\"Says the Annies List political group supports third-trimester abortions on demand.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature 3:  Sensational Feature Analysis\n",
    "\n",
    "#### [Sensational Words Corpus](https://www.thepersuasionrevolution.com/380-high-emotion-persuasive-words/)\n",
    "\n",
    ">  Words aren’t just strings of alphabets sewn together with ink. Words are cues. Words are triggers. Words when used correctly can transform an “eh whatever” into “wow that’s it!”. Words can make you go from literally ROFL to fuming with fury to an uncontrollable-urge-to-take-action-NOW-or-the-earth-may-stop-swinging -on-its-axis.\n",
    "\n",
    "> Highly emotional words are capable capable of transforming an absolute no into almost yes and a “perhaps” into “for sure”!\n",
    "\n",
    "Words that are used:\n",
    "- When you are trying to sell people a solution\n",
    "- When you are trying to get them to take an action (like, share, subscribe, buy)\n",
    "- When you are trying to get people to click and read your article\n",
    "- When you are trying to get someone to agree with you\n",
    "\n",
    "**There are 1400+ words that are both positive and negative emotions that will help to predict the sensational score for an article**\n",
    "\n",
    "> I have used these words to perform cosin similarity and predict the sensational similarity score for each news in the give dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnNames = [\"jsonid\", \"label\", \"headline_text\", \"subject\", \"speaker\", \"speaker_job_title\", \"state_info\", \"party_affiliation\", \"barely_true_counts\", \"false_counts\", \"half_true_counts\", \"mostly_true_counts\", \"pants_on_fire_counts\", \"context\",\"clean\", \"sentiment_vector\",\"vader_polarity\", \"sentiment_score\", \"index\", \"topic_number\", \"lda_score\", \"topic_top_words\"]\n",
    "dataTrain = pd.read_csv('input_data/train_lda.csv', sep=',', header=None, names = columnNames)\n",
    "dataTest = pd.read_csv('input_data/test_lda.csv', sep=',', header=None, names = columnNames)\n",
    "\n",
    "#dropping columns\n",
    "columnsToRemove = ['jsonid', 'label', 'subject', 'speaker','speaker_job_title', 'state_info', 'party_affiliation', 'barely_true_counts', 'false_counts', 'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts', 'context', 'sentiment_vector', 'sentiment_vector','vader_polarity', 'sentiment_score', 'index', 'topic_number', 'lda_score', 'topic_top_words']\n",
    "train_news = dataTrain.drop(columns=columnsToRemove)\n",
    "test_news = dataTest.drop(columns=columnsToRemove)\n",
    "train_news = train_news.loc[1:] \n",
    "test_news = test_news.loc[1:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "for i in train_news['clean']:\n",
    "    corpus.append(i)\n",
    "# corpus\n",
    "\n",
    "sensational_corpus=[]\n",
    "sensational_words = pd.read_csv('input_data/sensationalism/sensational_words_dict.csv', sep=\"\\t+\", header=None, usecols=[0] )\n",
    "print(len(sensational_words))\n",
    "sensational_dictionary = ' '.join(sensational_words[0].astype(str))\n",
    "sensational_corpus.append(sensational_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SenticNet:   \n",
    "\n",
    "#### Data Enrichment \n",
    "\n",
    "> It provides polarity associated with 50,000 natural language concepts. A polarity is a floating number between -1 and +1. Minus one is extreme negativity, and plus one is extreme positivity. The knowledge base is free. It can be downloaded as XML file. \n",
    "SenticNet 5 reaches 100,000 commonsense concepts by employing recurrent neural networks to infer primitives by lexical substitution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senticnet Vocab Size:  39891\n",
      "         Token  Polarity  Intensity\n",
      "0      abandon  negative      -0.84\n",
      "1    abandoned  negative      -0.85\n",
      "2  abandonment  negative      -0.82\n",
      "3        abase  negative      -0.90\n",
      "4    abasement  negative      -0.90\n",
      "5        abash  negative      -0.77\n",
      "6      abashed  negative      -0.92\n",
      "7    abashment  negative      -0.76\n",
      "8       abasia  negative      -0.67\n",
      "9        abate  negative      -0.86\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sentic_net = pd.read_csv('input_data/sensationalism/senticnet5.txt', sep=\"\\t+\", header=None, usecols=[0,1,2], names = [\"Token\", \"Polarity\", \"Intensity\"])\n",
    "sentic_net = sentic_net[~sentic_net['Token'].str.contains('|'.join('_'),na=False)]\n",
    "sentic_net = sentic_net.reset_index(drop=True)\n",
    "print(\"Senticnet Vocab Size: \",len(sentic_net))\n",
    "print(sentic_net.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2040\n"
     ]
    }
   ],
   "source": [
    "# sentic_net['Token'] provides list of words from the SenticNet DICTIONARY\n",
    "senti_pos = sentic_net.loc[sentic_net.Polarity == \"positive\"]\n",
    "senti_pos = senti_pos.loc[senti_pos.Intensity > 0.90]\n",
    "dictionary = ' '.join(senti_pos.Token.astype(str))\n",
    "sensational_corpus.append(dictionary)\n",
    "print(len(senti_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF and Cosine Similarity\n",
    "\n",
    "#### TF-IDF\n",
    "\n",
    "> TF-IDF (Term Frequency - Inverse Document Frequency) can be represented tf(d,t) X idf(t). TF-IDF uses the method diminishing the weight (importance) of words appeared in many documents in common, considered them incapable of discerning the documents, rather than simply counting the frequency of words as CountVectorizer does. The outcome matrix consists of each document (row) and each word (column) and the importance (weight) computed by tf * idf (values of the matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidfVec = TfidfVectorizer(max_features=1000)\n",
    "\n",
    "tfidf_corpus = tfidfVec.fit_transform(corpus)\n",
    "tf_idf_senti = tfidfVec.fit_transform(sensational_corpus)\n",
    "words = tfidfVec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_corpus.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02934579, 0.05869158, 0.05869158, ..., 0.        , 0.        ,\n",
       "        0.08803737],\n",
       "       [0.        , 0.        , 0.        , ..., 0.19269152, 0.06423051,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_senti.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'absolutely': 1,\n",
       " 'advantage': 3,\n",
       " 'qaeda': 742,\n",
       " 'amazing': 4,\n",
       " 'antagonistic': 6,\n",
       " 'attack': 14,\n",
       " 'authentic': 15,\n",
       " 'authority': 16,\n",
       " 'banned': 21,\n",
       " 'behind': 24,\n",
       " 'the': 929,\n",
       " 'scenes': 881,\n",
       " 'best': 26,\n",
       " 'bill': 28,\n",
       " 'bitterness': 29,\n",
       " 'black': 31,\n",
       " 'market': 187,\n",
       " 'blacklisted': 32,\n",
       " 'blissful': 34,\n",
       " 'up': 990,\n",
       " 'breathtaking': 37,\n",
       " 'campaign': 40,\n",
       " 'for': 95,\n",
       " 'censored': 42,\n",
       " 'cheer': 44,\n",
       " 'cheerful': 45,\n",
       " 'church': 47,\n",
       " 'class': 48,\n",
       " 'concealed': 52,\n",
       " 'confessions': 53,\n",
       " 'confidential': 55,\n",
       " 'control': 59,\n",
       " 'controversial': 61,\n",
       " 'cost': 62,\n",
       " 'cover': 63,\n",
       " 'crime': 64,\n",
       " 'critical': 65,\n",
       " 'infrastructure': 126,\n",
       " 'cyber': 67,\n",
       " 'security': 886,\n",
       " 'terror': 928,\n",
       " 'daring': 68,\n",
       " 'of': 388,\n",
       " 'desire': 71,\n",
       " 'disastrous': 72,\n",
       " 'drug': 76,\n",
       " 'ecstatic': 79,\n",
       " 'on': 409,\n",
       " 'emergency': 81,\n",
       " 'response': 859,\n",
       " 'enforcement': 83,\n",
       " 'eye': 85,\n",
       " 'opening': 415,\n",
       " 'faith': 86,\n",
       " 'faithfulness': 87,\n",
       " 'fbi': 89,\n",
       " 'first': 93,\n",
       " 'responder': 858,\n",
       " 'high': 118,\n",
       " 'forbidden': 96,\n",
       " 'force': 97,\n",
       " 'fire': 92,\n",
       " 'foul': 99,\n",
       " 'freedom': 101,\n",
       " 'gas': 104,\n",
       " 'gleeful': 107,\n",
       " 'grateful': 112,\n",
       " 'grid': 113,\n",
       " 'gun': 114,\n",
       " 'heart': 116,\n",
       " 'hidden': 117,\n",
       " 'horrific': 120,\n",
       " 'immigration': 122,\n",
       " 'inquiring': 127,\n",
       " 'mind': 253,\n",
       " 'insider': 128,\n",
       " 'investment': 131,\n",
       " 'inviolability': 132,\n",
       " 'jubilant': 133,\n",
       " 'keen': 134,\n",
       " 'law': 136,\n",
       " 'light': 140,\n",
       " 'lunatic': 147,\n",
       " 'lurking': 151,\n",
       " 'lying': 154,\n",
       " 'mad': 160,\n",
       " 'magic': 161,\n",
       " 'malware': 174,\n",
       " 'markets': 188,\n",
       " 'marriage': 193,\n",
       " 'maul': 210,\n",
       " 'meddlesome': 217,\n",
       " 'media': 218,\n",
       " 'merry': 234,\n",
       " 'mexico': 244,\n",
       " 'military': 249,\n",
       " 'militia': 250,\n",
       " 'blowing': 35,\n",
       " 'miracle': 258,\n",
       " 'mistake': 265,\n",
       " 'money': 276,\n",
       " 'motivation': 288,\n",
       " 'murder': 300,\n",
       " 'muse': 302,\n",
       " 'naked': 310,\n",
       " 'narcotics': 313,\n",
       " 'nation': 319,\n",
       " 'national': 320,\n",
       " 'preparedness': 652,\n",
       " 'nations': 321,\n",
       " 'naughty': 325,\n",
       " 'need': 327,\n",
       " 'news': 339,\n",
       " 'newsmonger': 342,\n",
       " 'nightmare': 346,\n",
       " 'no': 351,\n",
       " 'obligation': 375,\n",
       " 'questions': 751,\n",
       " 'strings': 914,\n",
       " 'nosiness': 365,\n",
       " 'notion': 367,\n",
       " 'nuclear': 370,\n",
       " 'threat': 931,\n",
       " 'numbers': 371,\n",
       " 'obama': 372,\n",
       " 'obnoxious': 376,\n",
       " 'offensive': 391,\n",
       " 'official': 394,\n",
       " 'officials': 395,\n",
       " 'officiousness': 397,\n",
       " 'off': 389,\n",
       " 'oil': 399,\n",
       " 'oklahoma': 403,\n",
       " 'nine': 348,\n",
       " 'organized': 427,\n",
       " 'outage': 434,\n",
       " 'outbreak': 435,\n",
       " 'outlawed': 440,\n",
       " 'outrage': 447,\n",
       " 'overjoyed': 465,\n",
       " 'painful': 478,\n",
       " 'parents': 501,\n",
       " 'parties': 506,\n",
       " 'passion': 508,\n",
       " 'patients': 516,\n",
       " 'payback': 520,\n",
       " 'peace': 521,\n",
       " 'peaceful': 522,\n",
       " 'peeping': 527,\n",
       " 'peril': 545,\n",
       " 'perky': 548,\n",
       " 'perpetuation': 550,\n",
       " 'phishing': 561,\n",
       " 'phobia': 562,\n",
       " 'played': 580,\n",
       " 'playful': 581,\n",
       " 'plummet': 588,\n",
       " 'poison': 596,\n",
       " 'police': 598,\n",
       " 'policies': 600,\n",
       " 'policy': 601,\n",
       " 'politics': 603,\n",
       " 'poll': 604,\n",
       " 'population': 617,\n",
       " 'pound': 636,\n",
       " 'power': 638,\n",
       " 'praise': 641,\n",
       " 'preposterous': 654,\n",
       " 'preserve': 659,\n",
       " 'president': 660,\n",
       " 'price': 664,\n",
       " 'prices': 665,\n",
       " 'primary': 666,\n",
       " 'prison': 670,\n",
       " 'privacy': 672,\n",
       " 'private': 673,\n",
       " 'progress': 688,\n",
       " 'projects': 689,\n",
       " 'promise': 693,\n",
       " 'promote': 694,\n",
       " 'prop': 697,\n",
       " 'propose': 701,\n",
       " 'protected': 707,\n",
       " 'proven': 712,\n",
       " 'provocative': 715,\n",
       " 'prurience': 717,\n",
       " 'prying': 719,\n",
       " 'psych': 721,\n",
       " 'punish': 733,\n",
       " 'questioning': 749,\n",
       " 'race': 760,\n",
       " 'rage': 766,\n",
       " 'raise': 768,\n",
       " 'rally': 770,\n",
       " 'rankle': 772,\n",
       " 'rate': 775,\n",
       " 'reason': 779,\n",
       " 'reassure': 781,\n",
       " 'recession': 784,\n",
       " 'proof': 696,\n",
       " 'recommend': 788,\n",
       " 'recovery': 792,\n",
       " 'reform': 810,\n",
       " 'refresh': 811,\n",
       " 'refund': 813,\n",
       " 'regard': 814,\n",
       " 'reliability': 826,\n",
       " 'republican': 841,\n",
       " 'republicans': 842,\n",
       " 'research': 846,\n",
       " 'resentment': 850,\n",
       " 'restrictions': 864,\n",
       " 'results': 867,\n",
       " 'revelation': 875,\n",
       " 'scandalous': 880,\n",
       " 'self': 887,\n",
       " 'indulgence': 125,\n",
       " 'sensational': 888,\n",
       " 'sensual': 891,\n",
       " 'sex': 894,\n",
       " 'and': 5,\n",
       " 'tired': 935,\n",
       " 'silly': 898,\n",
       " 'spectacular': 905,\n",
       " 'state': 909,\n",
       " 'stir': 911,\n",
       " 'stock': 912,\n",
       " 'stunning': 916,\n",
       " 'suicide': 918,\n",
       " 'sunny': 919,\n",
       " 'suspicious': 923,\n",
       " 'tantalizing': 925,\n",
       " 'tawdry': 926,\n",
       " 'thirst': 930,\n",
       " 'knowledge': 135,\n",
       " 'thrilling': 933,\n",
       " 'tickled': 934,\n",
       " 'tornado': 948,\n",
       " 'toxic': 958,\n",
       " 'trafficking': 959,\n",
       " 'transparency': 967,\n",
       " 'transportation': 968,\n",
       " 'trap': 969,\n",
       " 'tremor': 976,\n",
       " 'trepidation': 979,\n",
       " 'trial': 981,\n",
       " 'trustworthiness': 985,\n",
       " 'you': 999,\n",
       " 'unconditional': 988,\n",
       " 'upbeat': 991,\n",
       " 'urge': 993,\n",
       " 'wonderful': 995,\n",
       " 'world': 996,\n",
       " 'secret': 885,\n",
       " 'underground': 989,\n",
       " 'one': 410,\n",
       " 'plot': 586,\n",
       " 'record': 791,\n",
       " 'unbelievable': 986,\n",
       " 'magical': 162,\n",
       " 'instantly': 129,\n",
       " 'missing': 264,\n",
       " 'out': 433,\n",
       " 'magnificent': 164,\n",
       " 'most': 285,\n",
       " 'profitable': 686,\n",
       " 'quick': 752,\n",
       " 'remarkable': 833,\n",
       " 'startling': 908,\n",
       " 'strongly': 915,\n",
       " 'superb': 920,\n",
       " 'tremendous': 975,\n",
       " 'bargain': 22,\n",
       " 'discount': 73,\n",
       " 'reduced': 802,\n",
       " 'skyrocket': 902,\n",
       " 'perplexed': 551,\n",
       " 'misgiving': 261,\n",
       " 'manipulative': 180,\n",
       " 'paralyzed': 499,\n",
       " 'pathetic': 514,\n",
       " 'overwhelmed': 469,\n",
       " 'trapped': 971,\n",
       " 'panicked': 489,\n",
       " 'ordeal': 425,\n",
       " 'outrageousness': 449,\n",
       " 'provoke': 716,\n",
       " 'repulsive': 844,\n",
       " 'shocking': 897,\n",
       " 'tragic': 960,\n",
       " 'dreadful': 75,\n",
       " 'controlling': 60,\n",
       " 'resentful': 849,\n",
       " 'malicious': 170,\n",
       " 'repulsed': 843,\n",
       " 'quarrelsome': 747,\n",
       " 'rebellious': 782,\n",
       " 'poisonous': 597,\n",
       " 'retaliating': 868,\n",
       " 'reprimanding': 840,\n",
       " 'powerless': 640,\n",
       " 'pessimistic': 556,\n",
       " 'cut': 66,\n",
       " 'certain': 43,\n",
       " 'confident': 54,\n",
       " 'delighted': 70,\n",
       " 'effective': 80,\n",
       " 'conscientious': 56,\n",
       " 'approving': 8,\n",
       " 'honored': 119,\n",
       " 'privileged': 674,\n",
       " 'adaptable': 2,\n",
       " 'relaxed': 824,\n",
       " 'astonishing': 12,\n",
       " 'assured': 11,\n",
       " 'fulfilled': 102,\n",
       " 'genuine': 106,\n",
       " 'sufficient': 917,\n",
       " 'reliable': 827,\n",
       " 'sure': 922,\n",
       " 'excellent': 84,\n",
       " 'responsible': 861,\n",
       " 'trusting': 984,\n",
       " 'supported': 921,\n",
       " 'humility': 121,\n",
       " 'glorious': 108,\n",
       " 'like': 141,\n",
       " 'top': 946,\n",
       " 'optimistic': 420,\n",
       " 'spirited': 906,\n",
       " 'funny': 103,\n",
       " 'intelligent': 130,\n",
       " 'resourceful': 854,\n",
       " 'at': 13,\n",
       " 'ease': 78,\n",
       " 'comfortable': 50,\n",
       " 'pleased': 583,\n",
       " 'content': 58,\n",
       " 'serene': 892,\n",
       " 'bright': 38,\n",
       " 'blessed': 33,\n",
       " 'glowing': 109,\n",
       " 'motivated': 287,\n",
       " 'earnest': 77,\n",
       " 'brave': 36,\n",
       " 'clear': 49,\n",
       " 'balanced': 20,\n",
       " 'okay': 400,\n",
       " 'carefree': 41,\n",
       " 'forgiving': 98,\n",
       " 'sincere': 899,\n",
       " 'uplifted': 992,\n",
       " 'unburdened': 987,\n",
       " 'productive': 680,\n",
       " 'in': 124,\n",
       " 'responsive': 862,\n",
       " 'calm': 39,\n",
       " 'quiet': 754,\n",
       " 'radiant': 763,\n",
       " 'reflective': 808,\n",
       " 'open': 414,\n",
       " 'minded': 254,\n",
       " 'non': 359,\n",
       " 'aware': 17,\n",
       " 'meditative': 222,\n",
       " 'rested': 863,\n",
       " 'natural': 323,\n",
       " 'placid': 576,\n",
       " 'lurid': 149,\n",
       " 'arresting': 10,\n",
       " 'sensationalistic': 889,\n",
       " 'bizarre': 30,\n",
       " 'memorable': 224,\n",
       " 'riveting': 878,\n",
       " 'outrageous': 448,\n",
       " 'titillating': 936,\n",
       " 'perceptual': 536,\n",
       " 'sense': 890,\n",
       " 'resent': 848,\n",
       " 'publicized': 726,\n",
       " 'marred': 192,\n",
       " 'misses': 263,\n",
       " 'perceptible': 533,\n",
       " 'outing': 438,\n",
       " 'perceptive': 535,\n",
       " 'questionable': 748,\n",
       " 'macabre': 158,\n",
       " 'feel': 91,\n",
       " 'moments': 274,\n",
       " 'peaty': 523,\n",
       " 'nasty': 316,\n",
       " 'tactile': 924,\n",
       " 'modality': 269,\n",
       " 'overshadowed': 466,\n",
       " 'touchy': 955,\n",
       " 'mistakes': 266,\n",
       " 'mediocre': 221,\n",
       " 'olfactory': 408,\n",
       " 'match': 207,\n",
       " 'posting': 631,\n",
       " 'nociception': 352,\n",
       " 'smell': 903,\n",
       " 'perception': 534,\n",
       " 'nasute': 317,\n",
       " 'noisome': 357,\n",
       " 'macrosmatic': 159,\n",
       " 'pong': 611,\n",
       " 'redolent': 801,\n",
       " 'low': 142,\n",
       " 'scoring': 883,\n",
       " 'odour': 387,\n",
       " 'perceptualize': 537,\n",
       " 'five': 94,\n",
       " 'set': 893,\n",
       " 'olfaction': 406,\n",
       " 'stink': 910,\n",
       " 'odor': 383,\n",
       " 'marvelous': 199,\n",
       " 'scent': 882,\n",
       " 'nonfeeling': 360,\n",
       " 'phenomenal': 559,\n",
       " 'aroma': 9,\n",
       " 'sniff': 904,\n",
       " 'percipient': 538,\n",
       " 'pathos': 515,\n",
       " 'perceive': 531,\n",
       " 'palpable': 484,\n",
       " 'miscue': 260,\n",
       " 'touch': 950,\n",
       " 'nonsensical': 362,\n",
       " 'awareness': 18,\n",
       " 'malodorous': 173,\n",
       " 'needlefelt': 328,\n",
       " 'emotionally': 82,\n",
       " 'olfactometer': 407,\n",
       " 'pungency': 732,\n",
       " 'toucher': 952,\n",
       " 'pongy': 612,\n",
       " 'odorous': 386,\n",
       " 'striking': 913,\n",
       " 'conscious': 57,\n",
       " 'ostentatious': 432,\n",
       " 'perfume': 542,\n",
       " 'title': 938,\n",
       " 'proprioception': 703,\n",
       " 'odorant': 384,\n",
       " 'palp': 483,\n",
       " 'niffy': 344,\n",
       " 'malodor': 172,\n",
       " 'odorize': 385,\n",
       " 'mouthgasm': 290,\n",
       " 'touchable': 951,\n",
       " 'perceivedness': 532,\n",
       " 'splendid': 907,\n",
       " 'mesmerizing': 238,\n",
       " 'gutsy': 115,\n",
       " 'masterful': 204,\n",
       " 'nerveless': 333,\n",
       " 'masterly': 205,\n",
       " 'miraculous': 259,\n",
       " 'torrid': 949,\n",
       " 'outlandish': 439,\n",
       " 'mesmeric': 236,\n",
       " 'palpate': 486,\n",
       " 'over': 459,\n",
       " 'titillation': 937,\n",
       " 'reek': 804,\n",
       " 'misperceive': 262,\n",
       " 'rat': 774,\n",
       " 'six': 900,\n",
       " 'fee': 90,\n",
       " 'down': 74,\n",
       " 'property': 699,\n",
       " 'common': 51,\n",
       " 'topic': 947,\n",
       " 'mental': 228,\n",
       " 'object': 373,\n",
       " 'nose': 364,\n",
       " 'multi': 292,\n",
       " 'abandon': 0,\n",
       " 'to': 941,\n",
       " 'anti': 7,\n",
       " 'beefed': 23,\n",
       " 'better': 27,\n",
       " 'rimmed': 877,\n",
       " 'ranging': 771,\n",
       " 'chosen': 46,\n",
       " 'going': 110,\n",
       " 'away': 19,\n",
       " 'shaking': 895,\n",
       " 'far': 88,\n",
       " 'length': 137,\n",
       " 'year': 997,\n",
       " 'old': 405,\n",
       " 'four': 100,\n",
       " 'genre': 105,\n",
       " 'bending': 25,\n",
       " 'grade': 111,\n",
       " 'lidded': 138,\n",
       " 'tech': 927,\n",
       " 'quality': 745,\n",
       " 'impressionism': 123,\n",
       " 'life': 139,\n",
       " 'shattering': 896,\n",
       " 'lowball': 143,\n",
       " 'lowliest': 144,\n",
       " 'lucky': 145,\n",
       " 'lunar': 146,\n",
       " 'lunchbox': 148,\n",
       " 'luridly': 150,\n",
       " 'lusty': 152,\n",
       " 'lutenist': 153,\n",
       " 'lynx': 155,\n",
       " 'lyricist': 156,\n",
       " 'mabbutt': 157,\n",
       " 'magician': 163,\n",
       " 'mahmudvand': 165,\n",
       " 'mailserver': 166,\n",
       " 'mailto': 167,\n",
       " 'mainframe': 168,\n",
       " 'maintainable': 169,\n",
       " 'malignaggi': 171,\n",
       " 'mama': 175,\n",
       " 'mammoth': 176,\n",
       " 'managerial': 177,\n",
       " 'mandatum': 178,\n",
       " 'manhattan': 179,\n",
       " 'manly': 181,\n",
       " 'mannersmith': 182,\n",
       " 'manorial': 183,\n",
       " 'manufacturing': 184,\n",
       " 'mapping': 185,\n",
       " 'marijuana': 186,\n",
       " 'marksmanship': 189,\n",
       " 'marksmen': 190,\n",
       " 'marquessate': 191,\n",
       " 'married': 194,\n",
       " 'marry': 195,\n",
       " 'marsh': 196,\n",
       " 'marshland': 197,\n",
       " 'martian': 198,\n",
       " 'marxism': 200,\n",
       " 'marxist': 201,\n",
       " 'masonry': 202,\n",
       " 'masterclass': 203,\n",
       " 'mastodon': 206,\n",
       " 'matinee': 208,\n",
       " 'matured': 209,\n",
       " 'maximal': 211,\n",
       " 'maximize': 212,\n",
       " 'mdewakanton': 213,\n",
       " 'meaning': 214,\n",
       " 'measurable': 215,\n",
       " 'mechanical': 216,\n",
       " 'medical': 219,\n",
       " 'medicinally': 220,\n",
       " 'membrane': 223,\n",
       " 'menarche': 225,\n",
       " 'menopause': 226,\n",
       " 'menstruate': 227,\n",
       " 'mentality': 229,\n",
       " 'mercifulness': 230,\n",
       " 'merger': 231,\n",
       " 'merino': 232,\n",
       " 'merlin': 233,\n",
       " 'mesclun': 235,\n",
       " 'mesmerise': 237,\n",
       " 'metaphysician': 239,\n",
       " 'metastable': 240,\n",
       " 'methodically': 241,\n",
       " 'methodology': 242,\n",
       " 'meticulously': 243,\n",
       " 'midair': 245,\n",
       " 'middle': 246,\n",
       " 'middling': 247,\n",
       " 'migration': 248,\n",
       " 'milkmaid': 251,\n",
       " 'miniaturist': 256,\n",
       " 'minimalistic': 257,\n",
       " 'mladost': 267,\n",
       " 'modal': 268,\n",
       " 'mode': 270,\n",
       " 'modern': 271,\n",
       " 'day': 69,\n",
       " 'modish': 272,\n",
       " 'molestation': 273,\n",
       " 'momentum': 275,\n",
       " 'moneybelt': 277,\n",
       " 'mood': 278,\n",
       " 'moon': 279,\n",
       " 'moondust': 280,\n",
       " 'moonshine': 281,\n",
       " 'moonshiner': 282,\n",
       " 'moralist': 283,\n",
       " 'mordancy': 284,\n",
       " 'motivate': 286,\n",
       " 'motto': 289,\n",
       " 'much': 291,\n",
       " 'multidimensional': 293,\n",
       " 'multidimensionality': 294,\n",
       " 'multidisciplinary': 295,\n",
       " 'multimillionaire': 296,\n",
       " 'multimodal': 297,\n",
       " 'multimodality': 298,\n",
       " 'mummy': 299,\n",
       " 'musclehead': 301,\n",
       " 'mushroom': 303,\n",
       " 'music': 304,\n",
       " 'musician': 305,\n",
       " 'musicologist': 306,\n",
       " 'muskrat': 307,\n",
       " 'mythology': 308,\n",
       " 'nab': 309,\n",
       " 'nambla': 311,\n",
       " 'napredak': 312,\n",
       " 'narration': 314,\n",
       " 'nasalization': 315,\n",
       " 'natatorium': 318,\n",
       " 'nattily': 322,\n",
       " 'naturally': 324,\n",
       " 'necessarily': 326,\n",
       " 'needly': 329,\n",
       " 'needs': 330,\n",
       " 'neferkare': 331,\n",
       " 'nest': 334,\n",
       " 'netiquette': 335,\n",
       " 'neuron': 336,\n",
       " 'neutrally': 337,\n",
       " 'newletter': 338,\n",
       " 'newsletter': 340,\n",
       " 'newsline': 341,\n",
       " 'newsworthy': 343,\n",
       " 'nightie': 345,\n",
       " 'nikah': 347,\n",
       " 'nipping': 349,\n",
       " 'nirvana': 350,\n",
       " 'noctural': 353,\n",
       " 'nocturnal': 354,\n",
       " 'nocturnality': 355,\n",
       " 'nocturnally': 356,\n",
       " 'nomological': 358,\n",
       " 'negotiable': 332,\n",
       " 'nonnegotiable': 361,\n",
       " 'northsouthnet': 363,\n",
       " 'nous': 368,\n",
       " 'novella': 369,\n",
       " 'oblate': 374,\n",
       " 'obsequious': 377,\n",
       " 'observer': 378,\n",
       " 'obsessiveness': 379,\n",
       " 'obstruent': 380,\n",
       " 'occasionalism': 381,\n",
       " 'occultist': 382,\n",
       " 'offensif': 390,\n",
       " 'offering': 392,\n",
       " 'officemax': 393,\n",
       " 'officiant': 396,\n",
       " 'oh': 398,\n",
       " 'okeh': 401,\n",
       " 'okey': 402,\n",
       " 'okonomiyaki': 404,\n",
       " 'ontological': 411,\n",
       " 'ontologically': 412,\n",
       " 'oot': 413,\n",
       " 'operate': 416,\n",
       " 'optimal': 417,\n",
       " 'optimality': 418,\n",
       " 'optimist': 419,\n",
       " 'optimize': 421,\n",
       " 'optimum': 422,\n",
       " 'orbit': 423,\n",
       " 'orbital': 424,\n",
       " 'organdy': 426,\n",
       " 'organza': 428,\n",
       " 'ornately': 429,\n",
       " 'orthodoxly': 430,\n",
       " 'oscillococcinum': 431,\n",
       " 'outdistance': 436,\n",
       " 'outdo': 437,\n",
       " 'outpace': 441,\n",
       " 'outperform': 442,\n",
       " 'outperformance': 443,\n",
       " 'outperformer': 444,\n",
       " 'outpoint': 445,\n",
       " 'outputted': 446,\n",
       " 'outrun': 450,\n",
       " 'outshine': 451,\n",
       " 'outshout': 452,\n",
       " 'outstay': 453,\n",
       " 'outstayed': 454,\n",
       " 'outstaying': 455,\n",
       " 'outstays': 456,\n",
       " 'outstrip': 457,\n",
       " 'oval': 458,\n",
       " 'overabundance': 460,\n",
       " 'overconsumption': 461,\n",
       " 'overgraze': 462,\n",
       " 'overindulgence': 463,\n",
       " 'overindulging': 464,\n",
       " 'overstays': 467,\n",
       " 'overturn': 468,\n",
       " 'owl': 470,\n",
       " 'owlish': 471,\n",
       " 'oxygen': 472,\n",
       " 'pabulum': 473,\n",
       " 'pachinko': 474,\n",
       " 'pacifism': 475,\n",
       " 'paedophilia': 476,\n",
       " 'paedophilic': 477,\n",
       " 'painstakingly': 479,\n",
       " 'palatalization': 480,\n",
       " 'palindrome': 481,\n",
       " 'palmy': 482,\n",
       " 'palpably': 485,\n",
       " 'pander': 487,\n",
       " 'paneer': 488,\n",
       " 'pannage': 490,\n",
       " 'pantheist': 491,\n",
       " 'pantie': 492,\n",
       " 'panties': 493,\n",
       " 'papalii': 494,\n",
       " 'par': 495,\n",
       " 'parabolica': 496,\n",
       " 'paradigmatically': 497,\n",
       " 'paradoxalement': 498,\n",
       " 'pared': 500,\n",
       " 'parisian': 502,\n",
       " 'parramatta': 503,\n",
       " 'participate': 504,\n",
       " 'participation': 505,\n",
       " 'partizan': 507,\n",
       " 'passionflower': 509,\n",
       " 'pasted': 510,\n",
       " 'pasturage': 511,\n",
       " 'paternalism': 512,\n",
       " 'paternalistic': 513,\n",
       " 'patriarchal': 517,\n",
       " 'patriot': 518,\n",
       " 'patron': 519,\n",
       " 'pederast': 524,\n",
       " 'pedophile': 525,\n",
       " 'pedophilia': 526,\n",
       " 'penny': 528,\n",
       " 'peppermint': 529,\n",
       " 'pepsi': 530,\n",
       " 'perenelle': 539,\n",
       " 'performer': 541,\n",
       " 'peri': 543,\n",
       " 'perigee': 544,\n",
       " 'perimenopause': 546,\n",
       " 'periodical': 547,\n",
       " 'perl': 549,\n",
       " 'persevering': 552,\n",
       " 'person': 553,\n",
       " 'personnel': 554,\n",
       " 'perspicuous': 555,\n",
       " 'petal': 557,\n",
       " 'petsmart': 558,\n",
       " 'philosopher': 560,\n",
       " 'physiotherapist': 563,\n",
       " 'pianist': 564,\n",
       " 'piece': 565,\n",
       " 'pillow': 566,\n",
       " 'pioneer': 567,\n",
       " 'pitch': 568,\n",
       " 'perfect': 540,\n",
       " 'pithily': 569,\n",
       " 'pithy': 570,\n",
       " 'pitlane': 571,\n",
       " 'pixelation': 572,\n",
       " 'placenta': 574,\n",
       " 'placental': 575,\n",
       " 'plastering': 577,\n",
       " 'plastid': 578,\n",
       " 'plato': 579,\n",
       " 'please': 582,\n",
       " 'plenary': 584,\n",
       " 'pleseant': 585,\n",
       " 'plotline': 587,\n",
       " 'pluralize': 589,\n",
       " 'plush': 590,\n",
       " 'plushly': 591,\n",
       " 'plushness': 592,\n",
       " 'plushy': 593,\n",
       " 'plutocrat': 594,\n",
       " 'podiatrist': 595,\n",
       " 'policeman': 599,\n",
       " 'political': 602,\n",
       " 'pollination': 605,\n",
       " 'polly': 606,\n",
       " 'polygon': 607,\n",
       " 'polyhedron': 608,\n",
       " 'polymodal': 609,\n",
       " 'polysemy': 610,\n",
       " 'pontiac': 613,\n",
       " 'ponzu': 614,\n",
       " 'pool': 615,\n",
       " 'poppy': 616,\n",
       " 'pornography': 618,\n",
       " 'pornstar': 619,\n",
       " 'portraitist': 620,\n",
       " 'posit': 621,\n",
       " 'positively': 622,\n",
       " 'positiveness': 623,\n",
       " 'positiver': 624,\n",
       " 'positivity': 625,\n",
       " 'possess': 626,\n",
       " 'possessively': 627,\n",
       " 'post': 628,\n",
       " 'poster': 629,\n",
       " 'postgraduate': 630,\n",
       " 'poteen': 632,\n",
       " 'potpourri': 633,\n",
       " 'potty': 634,\n",
       " 'pouf': 635,\n",
       " 'powder': 637,\n",
       " 'powerade': 639,\n",
       " 'pranayama': 642,\n",
       " 'preach': 643,\n",
       " 'precede': 644,\n",
       " 'predominantly': 645,\n",
       " 'preemie': 646,\n",
       " 'preface': 647,\n",
       " 'preform': 648,\n",
       " 'pregnant': 649,\n",
       " 'premise': 650,\n",
       " 'preparation': 651,\n",
       " 'preponderant': 653,\n",
       " 'prepubertal': 655,\n",
       " 'prescience': 656,\n",
       " 'prescient': 657,\n",
       " 'present': 658,\n",
       " 'presuppose': 661,\n",
       " 'presupposition': 662,\n",
       " 'prewash': 663,\n",
       " 'primordially': 667,\n",
       " 'princess': 668,\n",
       " 'printmaker': 669,\n",
       " 'pristine': 671,\n",
       " 'prizefighter': 675,\n",
       " 'probability': 676,\n",
       " 'probity': 677,\n",
       " 'proboscis': 678,\n",
       " 'proceed': 679,\n",
       " 'prof': 681,\n",
       " 'professed': 682,\n",
       " 'professedly': 683,\n",
       " 'professor': 684,\n",
       " 'professorship': 685,\n",
       " 'profuse': 687,\n",
       " 'prolific': 690,\n",
       " 'promethean': 691,\n",
       " 'prominent': 692,\n",
       " 'promotional': 695,\n",
       " 'propeller': 698,\n",
       " 'proportionately': 700,\n",
       " 'propre': 702,\n",
       " 'prospectively': 704,\n",
       " 'prospering': 705,\n",
       " 'prosperity': 706,\n",
       " 'protection': 708,\n",
       " 'protocol': 709,\n",
       " 'proton': 710,\n",
       " 'provability': 711,\n",
       " 'providential': 713,\n",
       " 'providentially': 714,\n",
       " 'prutot': 718,\n",
       " 'pseudoknot': 720,\n",
       " 'psychatog': 722,\n",
       " 'psychologiquement': 723,\n",
       " 'pub': 724,\n",
       " 'puberty': 725,\n",
       " 'puir': 727,\n",
       " 'pun': 728,\n",
       " 'puncher': 729,\n",
       " 'punchline': 730,\n",
       " 'punctual': 731,\n",
       " 'pup': 734,\n",
       " 'purgative': 735,\n",
       " 'purge': 736,\n",
       " 'purposeful': 737,\n",
       " 'purposefully': 738,\n",
       " 'purposive': 739,\n",
       " 'push': 740,\n",
       " 'pushing': 741,\n",
       " 'quaintly': 743,\n",
       " 'qualify': 744,\n",
       " 'quantitatively': 746,\n",
       " 'questioningly': 750,\n",
       " 'quickener': 753,\n",
       " 'quileute': 755,\n",
       " 'quintessential': 756,\n",
       " 'quintessentially': 757,\n",
       " 'quizzically': 758,\n",
       " 'quote': 759,\n",
       " 'racy': 761,\n",
       " 'radiancy': 762,\n",
       " 'radicalism': 764,\n",
       " 'radniki': 765,\n",
       " 'raingear': 767,\n",
       " 'rakishly': 769,\n",
       " 'raper': 773,\n",
       " 'readably': 776,\n",
       " 'reaffirmation': 777,\n",
       " 'realist': 778,\n",
       " 'reasonably': 780,\n",
       " 'recent': 783,\n",
       " 'reclaim': 785,\n",
       " 'recognizable': 786,\n",
       " 'recolonization': 787,\n",
       " 'reconceive': 789,\n",
       " 'reconstitute': 790,\n",
       " 'recreation': 793,\n",
       " 'recreational': 794,\n",
       " 'rect': 795,\n",
       " 'rectangle': 796,\n",
       " 'redbud': 797,\n",
       " 'redemption': 798,\n",
       " 'redemptive': 799,\n",
       " 'redhead': 800,\n",
       " 'reducible': 803,\n",
       " 'reeperbahn': 805,\n",
       " 'reflectance': 806,\n",
       " 'reflectivity': 809,\n",
       " 'refridgerator': 812,\n",
       " 'regurgitated': 815,\n",
       " 'rehab': 816,\n",
       " 'rehabilitate': 817,\n",
       " 'rehabilitative': 818,\n",
       " 'rehearsal': 819,\n",
       " 'reinstate': 820,\n",
       " 'reinstated': 821,\n",
       " 'relativism': 822,\n",
       " 'relaxation': 823,\n",
       " 'relentlessness': 825,\n",
       " 'reliably': 828,\n",
       " 'reliever': 830,\n",
       " 'religionist': 831,\n",
       " 'relish': 832,\n",
       " 'remediate': 834,\n",
       " 'remedy': 835,\n",
       " 'renovation': 836,\n",
       " 'repair': 837,\n",
       " 'reponsible': 838,\n",
       " 'representative': 839,\n",
       " 'rescue': 845,\n",
       " 'resend': 847,\n",
       " 'resistless': 851,\n",
       " 'resoluteness': 852,\n",
       " 'resource': 853,\n",
       " 'respectful': 855,\n",
       " 'respiration': 856,\n",
       " 'resplendent': 857,\n",
       " 'responsibile': 860,\n",
       " 'restructure': 865,\n",
       " 'restructuring': 866,\n",
       " 'retell': 869,\n",
       " 'retold': 870,\n",
       " 'retroactive': 871,\n",
       " 'retroactively': 872,\n",
       " 'retrospectively': 873,\n",
       " 'reusable': 874,\n",
       " 'rich': 876,\n",
       " 'mill': 252,\n",
       " 'salutation': 879,\n",
       " 'second': 884,\n",
       " 'reflection': 807,\n",
       " 'reliant': 829,\n",
       " 'titled': 939,\n",
       " 'mindedness': 255,\n",
       " 'sky': 901,\n",
       " 'three': 932,\n",
       " 'tko': 940,\n",
       " 'toehold': 942,\n",
       " 'tomato': 943,\n",
       " 'tonkatsu': 944,\n",
       " 'toovey': 945,\n",
       " 'notch': 366,\n",
       " 'touchpad': 953,\n",
       " 'touchscreen': 954,\n",
       " 'tough': 956,\n",
       " 'tourism': 957,\n",
       " 'tram': 961,\n",
       " 'transcription': 962,\n",
       " 'transliterate': 963,\n",
       " 'transliterated': 964,\n",
       " 'transliterating': 965,\n",
       " 'transliteration': 966,\n",
       " 'trapezoid': 970,\n",
       " 'trapper': 972,\n",
       " 'treat': 973,\n",
       " 'trellis': 974,\n",
       " 'trenchant': 977,\n",
       " 'trendiest': 978,\n",
       " 'trepidly': 980,\n",
       " 'tribal': 982,\n",
       " 'tribe': 983,\n",
       " 'well': 994,\n",
       " 'placed': 573,\n",
       " 'yo': 998}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfVec.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dim: (10239, 1000)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Test dim: (1266, 1000)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "train_tfidf = tfidfVec.fit_transform(train_news['clean'])\n",
    "print('Training dim:', train_tfidf.shape)\n",
    "print(train_tfidf.A[:10])\n",
    "\n",
    "\n",
    "test_tfidf = tfidfVec.fit_transform(test_news['clean'])\n",
    "print('Test dim:', test_tfidf.shape)\n",
    "print(test_tfidf.A[:10])\n",
    "\n",
    "\n",
    "# valid_tfidf = tfidfVec.fit_transform(valid_news['clean'])\n",
    "# print('Valid dim:', valid_tfidf.shape)\n",
    "# print(valid_tfidf.A[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Cosine Similarity Score\n",
    "\n",
    "> The cosine similarity between two vectors (or two documents on the Vector Space) is a measure that calculates the cosine of the angle between them. This metric is a measurement of orientation and not magnitude, it can be seen as a comparison between documents on a normalized space because we’re not taking into the consideration only the magnitude of each word count (tf-idf) of each document, but the angle between the documents.\n",
    "\n",
    "> I have compared the sentiment vector of each doucment and estimated a similarity score which is saved as a column in the training and test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import spatial\n",
    "similarity_score = []\n",
    "for i in range(len(train_tfidf.toarray())):\n",
    "    similarity_score.append(1 - spatial.distance.cosine(tf_idf_senti[0].toarray(), tfidf_corpus[i].toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline_text</th>\n",
       "      <th>clean</th>\n",
       "      <th>sensational_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>decline coal start start natur gas took start ...</td>\n",
       "      <td>0.061786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>hillary clinton agre john mccain vote give geo...</td>\n",
       "      <td>0.059743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>health care reform legis like mandat free sex ...</td>\n",
       "      <td>0.052559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>econom turnaround start end term</td>\n",
       "      <td>0.066800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>The Chicago Bears have had more starting quart...</td>\n",
       "      <td>chicago bear start quarterback last year total...</td>\n",
       "      <td>0.048691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         headline_text  \\\n",
       "1.0  When did the decline of coal start? It started...   \n",
       "2.0  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "3.0  Health care reform legislation is likely to ma...   \n",
       "4.0  The economic turnaround started at the end of ...   \n",
       "5.0  The Chicago Bears have had more starting quart...   \n",
       "\n",
       "                                                 clean  sensational_score  \n",
       "1.0  decline coal start start natur gas took start ...           0.061786  \n",
       "2.0  hillary clinton agre john mccain vote give geo...           0.059743  \n",
       "3.0  health care reform legis like mandat free sex ...           0.052559  \n",
       "4.0                   econom turnaround start end term           0.066800  \n",
       "5.0  chicago bear start quarterback last year total...           0.048691  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_news['sensational_score'] = similarity_score\n",
    "train_news.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline_text</th>\n",
       "      <th>clean</th>\n",
       "      <th>sensational_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>Wisconsin is on pace to double the number of l...</td>\n",
       "      <td>wisconsin pace doubl number layoff year</td>\n",
       "      <td>0.019047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>Says John McCain has done nothing to help the ...</td>\n",
       "      <td>say john mccain done noth help vet</td>\n",
       "      <td>0.026551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>Suzanne Bonamici supports a plan that will cut...</td>\n",
       "      <td>suzanne bonamici support plan cut choice medic...</td>\n",
       "      <td>0.061022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>When asked by a reporter whether hes at the ce...</td>\n",
       "      <td>ask report whether he center crimini scheme vi...</td>\n",
       "      <td>0.065230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>Over the past five years the federal governmen...</td>\n",
       "      <td>past five year feder govern paid million retir...</td>\n",
       "      <td>0.066946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         headline_text  \\\n",
       "1.0  Wisconsin is on pace to double the number of l...   \n",
       "2.0  Says John McCain has done nothing to help the ...   \n",
       "3.0  Suzanne Bonamici supports a plan that will cut...   \n",
       "4.0  When asked by a reporter whether hes at the ce...   \n",
       "5.0  Over the past five years the federal governmen...   \n",
       "\n",
       "                                                 clean  sensational_score  \n",
       "1.0            wisconsin pace doubl number layoff year           0.019047  \n",
       "2.0                 say john mccain done noth help vet           0.026551  \n",
       "3.0  suzanne bonamici support plan cut choice medic...           0.061022  \n",
       "4.0  ask report whether he center crimini scheme vi...           0.065230  \n",
       "5.0  past five year feder govern paid million retir...           0.066946  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = []\n",
    "for i in test_news['clean']:\n",
    "    corpus.append(i)\n",
    "# corpus\n",
    "\n",
    "tfidf_corpus = tfidfVec.fit_transform(corpus)\n",
    "\n",
    "similarity_score = []\n",
    "for i in range(len(test_tfidf.toarray())):\n",
    "    similarity_score.append(1 - spatial.distance.cosine(tf_idf_senti[0].toarray(), tfidf_corpus[i].toarray()))\n",
    "    \n",
    "test_news['sensational_score'] = similarity_score\n",
    "test_news.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saved the latest dataset into a seperate CSV file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_news.to_csv(\"input_data/train_sensationalism.csv\", sep=',')\n",
    "test_news.to_csv(\"input_data/test_sensationalism.csv\", sep=',')\n",
    "valid_news.to_csv(\"input_data/valid_sensationalism.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jsonid</th>\n",
       "      <th>headline_text</th>\n",
       "      <th>clean</th>\n",
       "      <th>sensational_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>decline coal start start natur gas took start ...</td>\n",
       "      <td>0.0617855637213337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>hillary clinton agre john mccain vote give geo...</td>\n",
       "      <td>0.05974269381960995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>health care reform legis like mandat free sex ...</td>\n",
       "      <td>0.05255867153636662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>econom turnaround start end term</td>\n",
       "      <td>0.0667999552542814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>The Chicago Bears have had more starting quart...</td>\n",
       "      <td>chicago bear start quarterback last year total...</td>\n",
       "      <td>0.04869082661404933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   jsonid                                      headline_text  \\\n",
       "1     1.0  When did the decline of coal start? It started...   \n",
       "2     2.0  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "3     3.0  Health care reform legislation is likely to ma...   \n",
       "4     4.0  The economic turnaround started at the end of ...   \n",
       "5     5.0  The Chicago Bears have had more starting quart...   \n",
       "\n",
       "                                               clean    sensational_score  \n",
       "1  decline coal start start natur gas took start ...   0.0617855637213337  \n",
       "2  hillary clinton agre john mccain vote give geo...  0.05974269381960995  \n",
       "3  health care reform legis like mandat free sex ...  0.05255867153636662  \n",
       "4                   econom turnaround start end term   0.0667999552542814  \n",
       "5  chicago bear start quarterback last year total...  0.04869082661404933  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "columnNames = [\"jsonid\", \"headline_text\", \"clean\", \"sensational_score\"]\n",
    "dataTrain = pd.read_csv('input_data/train_sensationalism.csv', sep=',', header=None, names = columnNames)\n",
    "dataTest = pd.read_csv('input_data/test_sensationalism.csv', sep=',', header=None, names = columnNames)\n",
    "\n",
    "dataTrain = dataTrain.loc[1:]\n",
    "dataTest = dataTest.loc[1:]\n",
    "\n",
    "\n",
    "dataTrain.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensationalism Model Trained - accuracy:   0.031596\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import  LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.porter import *\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "\n",
    "class SensationalismFeature():\n",
    "\n",
    "    def __init__(self):        \n",
    "\n",
    "        columnNames = [\"jsonid\", \"headline_text\", \"clean\", \"sensational_score\"]\n",
    "        dataTrain = pd.read_csv('input_data/train_sensationalism.csv', sep=',', header=None, names = columnNames)\n",
    "        dataTest = pd.read_csv('input_data/test_sensationalism.csv', sep=',', header=None, names = columnNames)\n",
    "        dataTrain = dataTrain.loc[1:]\n",
    "        dataTest = dataTest.loc[1:]\n",
    "            \n",
    "        tfidfV = TfidfVectorizer(stop_words='english', min_df=5, max_df = 30, use_idf = True, smooth_idf = True, token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b')\n",
    "\n",
    "        self.logR_pipeline = Pipeline([\n",
    "                ('LogRCV', tfidfV),\n",
    "                ('LogR_clf', LogisticRegression(solver='liblinear', C = 32/100))\n",
    "                ])\n",
    "\n",
    "        self.logR_pipeline.fit(dataTrain['headline_text'], dataTrain['sensational_score'].astype(str))\n",
    "        predicted_LogR = self.logR_pipeline.predict(dataTest['headline_text'])\n",
    "        score = metrics.accuracy_score(dataTest['sensational_score'].astype(str), predicted_LogR)\n",
    "        print(\"Sensationalism Model Trained - accuracy:   %0.6f\" % score)\n",
    "        \n",
    "\n",
    "    def predict(self, text):\n",
    "        predicted = self.logR_pipeline.predict([text])\n",
    "        predicedProb = self.logR_pipeline.predict_proba([text])[:,1]\n",
    "        return bool(predicted), float(predicedProb)\n",
    "    \n",
    "    \n",
    "sf = SensationalismFeature()\n",
    "# sf.predict(\"Says the Annies List political group supports third-trimester abortions on demand.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010105770859692713\n"
     ]
    }
   ],
   "source": [
    "def DATAMINERS_getSensationalismScore(text):  # return between 0 and 1, being 0 = True,  1 = Fake\n",
    "    #print(clickBait.predict(\"Should You bring the money now\"))\n",
    "    binaryValue, probValue = sf.predict(text)\n",
    "    return (float(probValue*100))\n",
    "\n",
    "print(DATAMINERS_getSensationalismScore(\"Says the Annies List political group supports third-trimester abortions on demand.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature 4: Political Affiliation Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Party Affiliation Model Trained - accuracy:   0.565436\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import  LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.porter import *\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import  LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.cross_validation import KFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "class PartyAffiliation():\n",
    "    \n",
    "    # API to check whether the subject(Headline) is present in the \n",
    "    # - democrats most used words if the party affiliation is democrat\n",
    "    # - republicans most used words if the part affiliation is republican\n",
    "    def partyAffiliationFromHeadline(self, r):\n",
    "        v = r['subject_str']\n",
    "        p = r['party_str']\n",
    "        if (p =='democrat'):\n",
    "            s2 = set(self.countDemV.get_feature_names())\n",
    "        if (p =='republican'):\n",
    "            s2 = set(self.countRepV.get_feature_names())\n",
    "        if (p != 'democract' and p !='republican'):\n",
    "            return 1 #'true'        \n",
    "        if set(v).intersection(s2):\n",
    "            return 1 #'true'\n",
    "        else:\n",
    "            return 0 #'false'\n",
    "\n",
    "    #API to convert true, mostly-true and half-true to true\n",
    "    # false, barely-true and pants-fire to false\n",
    "    def convertMulticlassToBinaryclass(self, r):\n",
    "        v = r['label']\n",
    "        if (v == 'true'):\n",
    "            return 1 #'true'\n",
    "        if (v == 'mostly-true'):\n",
    "            return 1 #'true'\n",
    "        if (v == 'half-true'):\n",
    "            return 1 #'true'\n",
    "        if (v == 'barely-true'):\n",
    "            return 0 #'false'\n",
    "        if (v == 'false'):\n",
    "            return 0 #'false'\n",
    "        if (v == 'pants-fire'):\n",
    "            return 0 #'false'\n",
    "            \n",
    "            \n",
    "            \n",
    "    def plot_confusion_matrix(self, cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "        plt.title(title)\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(classes))\n",
    "        plt.xticks(tick_marks, classes, rotation=45)\n",
    "        plt.yticks(tick_marks, classes)\n",
    "\n",
    "        if normalize:\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            print(\"Normalized confusion matrix\")\n",
    "        else:\n",
    "            print('Confusion matrix, without normalization')\n",
    "\n",
    "        thresh = cm.max() / 2.\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            plt.text(j, i, cm[i, j],\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')       \n",
    "            \n",
    "    \n",
    "    def __init__(self):        \n",
    "\n",
    "        columnNamesPar = [\"id\", \"label\", \"statement\", \"subject\", \"speaker\", \"speaker_job_title\", \"state_info\", \"party_affiliation\", \"barely_true_counts\", \"false_counts\", \"half_true_counts\", \"mostly_true_counts\", \"pants_on_fire_counts\", \"context\"]\n",
    "        dataTrainPar = pd.read_csv('input_data/dataset/train.tsv', sep='\\t', header=None, names = columnNamesPar)\n",
    "        dataValidatePar = pd.read_csv('input_data/dataset/valid.tsv', sep='\\t', header=None, names = columnNamesPar)\n",
    "        dataTestPar = pd.read_csv('input_data/dataset/test.tsv', sep='\\t', header=None, names = columnNamesPar)\n",
    "        \n",
    "    \n",
    "        # Remove unwanted columns in the dataset\n",
    "        columnsToRemovePar = ['id', 'speaker', 'context','speaker_job_title', 'barely_true_counts', 'false_counts', 'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts']\n",
    "        dataTrainPar = dataTrainPar.drop(columns=columnsToRemovePar)\n",
    "        dataValidatePar = dataValidatePar.drop(columns=columnsToRemovePar)\n",
    "        dataTestPar = dataTestPar.drop(columns=columnsToRemovePar)\n",
    "        \n",
    "        # convert the labels to true and false only\n",
    "        dataTrainPar['label'] = dataTrainPar.apply(self.convertMulticlassToBinaryclass, axis=1)\n",
    "        dataValidatePar['label'] = dataValidatePar.apply(self.convertMulticlassToBinaryclass, axis=1)\n",
    "        dataTestPar['label'] = dataTestPar.apply(self.convertMulticlassToBinaryclass, axis=1)\n",
    "        \n",
    "        # display all the party affiliations and show the count of each party \n",
    "#         dataTrainPar.groupby('party_affiliation').count()[['state_info']].rename(\n",
    "#         columns={'state_info': 'count'}).sort_values(\n",
    "#         'count', ascending=False).reset_index().plot.bar(\n",
    "#         x='party_affiliation', y='count', figsize=(16, 10), fontsize=18);\n",
    "        \n",
    "        # As we are considering only democrat, republican and none (top 3 party affiliations),\n",
    "        # ignoring other party affiliations\n",
    "        rowsToRemove = ['Moderate', 'activist', 'business-leader', 'columnist', 'constitution-party', 'democratic-farmer-labor', 'education-official', 'government-body', 'green', 'independent', 'journalist', 'labor-leader', 'liberal-party-canada', 'libertarian', 'nan', 'newsmaker', 'ocean-state-tea-party-action', 'organization', 'state-official', 'talk-show-host', 'tea-party-member']\n",
    "\n",
    "        dataTrainPar = dataTrainPar[dataTrainPar.party_affiliation != 'Moderate']\n",
    "        dataTrainPar = dataTrainPar[dataTrainPar.party_affiliation != 'activist']\n",
    "        dataTrainPar = dataTrainPar[dataTrainPar.party_affiliation != 'business-leader']\n",
    "        dataTrainPar = dataTrainPar[dataTrainPar.party_affiliation != 'columnist']\n",
    "        dataTrainPar = dataTrainPar[dataTrainPar.party_affiliation != 'constitution-party']\n",
    "        dataTrainPar = dataTrainPar[dataTrainPar.party_affiliation != 'democratic-farmer-labor']\n",
    "        dataTrainPar = dataTrainPar[dataTrainPar.party_affiliation != 'education-official']\n",
    "        dataTrainPar = dataTrainPar[dataTrainPar.party_affiliation != 'government-body']\n",
    "        dataTrainPar = dataTrainPar[dataTrainPar.party_affiliation != 'green']\n",
    "        dataTrainPar = dataTrainPar[dataTrainPar.party_affiliation != 'independent']\n",
    "        dataTrainPar = dataTrainPar[dataTrainPar.party_affiliation != 'journalist']\n",
    "        dataTrainPar = dataTrainPar[dataTrainPar.party_affiliation != 'labor-leader']\n",
    "        dataTrainPar = dataTrainPar[dataTrainPar.party_affiliation != 'liberal-party-canada']\n",
    "        dataTrainPar = dataTrainPar[dataTrainPar.party_affiliation != 'libertarian']\n",
    "        dataTrainPar = dataTrainPar[dataTrainPar.party_affiliation != 'nan']\n",
    "        dataTrainPar = dataTrainPar[dataTrainPar.party_affiliation != 'newsmaker']\n",
    "        dataTrainPar = dataTrainPar[dataTrainPar.party_affiliation != 'ocean-state-tea-party-action']\n",
    "        dataTrainPar = dataTrainPar[dataTrainPar.party_affiliation != 'organization']\n",
    "        dataTrainPar = dataTrainPar[dataTrainPar.party_affiliation != 'state-official']\n",
    "        dataTrainPar = dataTrainPar[dataTrainPar.party_affiliation != 'talk-show-host']\n",
    "        dataTrainPar = dataTrainPar[dataTrainPar.party_affiliation != 'tea-party-member']\n",
    "\n",
    "        # As we are considering only democrat, republican and none (top 3 party affiliations),\n",
    "        # ignoring other party affiliations\n",
    "\n",
    "        dataTestPar = dataTestPar[dataTestPar.party_affiliation != 'Moderate']\n",
    "        dataTestPar = dataTestPar[dataTestPar.party_affiliation != 'activist']\n",
    "        dataTestPar = dataTestPar[dataTestPar.party_affiliation != 'business-leader']\n",
    "        dataTestPar = dataTestPar[dataTestPar.party_affiliation != 'columnist']\n",
    "        dataTestPar = dataTestPar[dataTestPar.party_affiliation != 'constitution-party']\n",
    "        dataTestPar = dataTestPar[dataTestPar.party_affiliation != 'democratic-farmer-labor']\n",
    "        dataTestPar = dataTestPar[dataTestPar.party_affiliation != 'education-official']\n",
    "        dataTestPar = dataTestPar[dataTestPar.party_affiliation != 'government-body']\n",
    "        dataTestPar = dataTestPar[dataTestPar.party_affiliation != 'green']\n",
    "        dataTestPar = dataTestPar[dataTestPar.party_affiliation != 'independent']\n",
    "        dataTestPar = dataTestPar[dataTestPar.party_affiliation != 'journalist']\n",
    "        dataTestPar = dataTestPar[dataTestPar.party_affiliation != 'labor-leader']\n",
    "        dataTestPar = dataTestPar[dataTestPar.party_affiliation != 'liberal-party-canada']\n",
    "        dataTestPar = dataTestPar[dataTestPar.party_affiliation != 'libertarian']\n",
    "        dataTestPar = dataTestPar[dataTestPar.party_affiliation != 'nan']\n",
    "        dataTestPar = dataTestPar[dataTestPar.party_affiliation != 'newsmaker']\n",
    "        dataTestPar = dataTestPar[dataTestPar.party_affiliation != 'ocean-state-tea-party-action']\n",
    "        dataTestPar = dataTestPar[dataTestPar.party_affiliation != 'organization']\n",
    "        dataTestPar = dataTestPar[dataTestPar.party_affiliation != 'state-official']\n",
    "        dataTestPar = dataTestPar[dataTestPar.party_affiliation != 'talk-show-host']\n",
    "        dataTestPar = dataTestPar[dataTestPar.party_affiliation != 'tea-party-member']\n",
    "\n",
    "        \n",
    "        dataTrainPar['party_str'] = dataTrainPar['party_affiliation'].astype(str)\n",
    "        dataTestPar['party_str'] = dataTestPar['party_affiliation'].astype(str)\n",
    "        \n",
    "\n",
    "        #predicting truth level\n",
    "#        dataTrainPar.groupby('label').count()[['party_affiliation']].reset_index().plot.bar(x='label', y='party_affiliation')\n",
    "        \n",
    "        # get the most used democrat words\n",
    "        self.countDemV = CountVectorizer(stop_words='english', min_df=40, max_df=80, token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b')\n",
    "\n",
    "        dataTrainDem= dataTrainPar\n",
    "        dataTrainDem = dataTrainPar.loc[dataTrainPar['party_str'] == 'democrat']\n",
    "        dem_count = self.countDemV.fit_transform(dataTrainDem['statement'].values)\n",
    "        \n",
    "        #get the republican most used words\n",
    "        \n",
    "        self.countRepV = CountVectorizer(stop_words='english', min_df=20, max_df=40, token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b')\n",
    "        dataTrainRep= dataTrainPar\n",
    "        dataTrainRep = dataTrainPar.loc[dataTrainPar['party_str'] == 'republican']\n",
    "        rep_count = self.countRepV.fit_transform(dataTrainRep['statement'].values)\n",
    "\n",
    "        dataTestDem= dataTestPar\n",
    "        dataTestDem = dataTestPar.loc[dataTestPar['party_str'] == 'democrat']\n",
    "        \n",
    "        dataTrainPar['subject_str'] = dataTrainPar['subject'].astype(str).str.split() \n",
    "        dataTrainPar['label_str'] = dataTrainPar.apply(self.partyAffiliationFromHeadline, axis=1)\n",
    "\n",
    "        dataTestPar['subject_str'] = dataTestPar['subject'].astype(str).str.split() \n",
    "        dataTestPar['label_str'] = dataTestPar.apply(self.partyAffiliationFromHeadline, axis=1)\n",
    "\n",
    "        dataTrainDem['subject_str'] = dataTrainDem['subject'].astype(str).str.split() \n",
    "        dataTrainDem['label_str'] = dataTrainDem.apply(self.partyAffiliationFromHeadline, axis=1)\n",
    "    \n",
    "        dataTestDem['subject_str'] = dataTestDem['subject'].astype(str).str.split() \n",
    "        dataTestDem['label_str'] = dataTestDem.apply(self.partyAffiliationFromHeadline, axis=1)\n",
    "        \n",
    "        \n",
    "        self.model = LogisticRegression()\n",
    "        self.model = self.model.fit(dataTrainPar['label_str'].values.reshape(-1, 1), dataTrainPar['label'].values)\n",
    "        predicted_LogR = self.model.predict(dataTestPar['label_str'].values.reshape(-1, 1))\n",
    "        score = metrics.accuracy_score(dataTestPar['label'], predicted_LogR)\n",
    "        print(\"Party Affiliation Model Trained - accuracy:   %0.6f\" % score)\n",
    "\n",
    "    \n",
    "    def predict(self, headline, party):\n",
    "                \n",
    "        #creating the dataframe with our text so we can leverage the existing code\n",
    "        dfrme = pd.DataFrame(index=[0], columns=['subject', 'party_str'])\n",
    "        dfrme['subject_str'] = headline\n",
    "        dfrme['party_str'] = party        \n",
    "\n",
    "        dfrme['subject'] = headline\n",
    "        dfrme['subject_str'] = dfrme['subject'].astype(str).str.split() \n",
    "        dfrme['label_str'] = dfrme.apply(self.partyAffiliationFromHeadline, axis=1)\n",
    "        \n",
    "        x = dfrme['label_str'].values.reshape(-1, 1)\n",
    "        predicted = self.model.predict(x)\n",
    "        predicedProb = self.model.predict_proba(x)[:,1]\n",
    "        return predicted, predicedProb\n",
    "                    \n",
    "    \n",
    "##testing code\n",
    "f = PartyAffiliation()\n",
    "#pf.predict(\"Says the Annies List political group supports third-trimester abortions on demand\", \"republican\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>canonical_link</th>\n",
       "      <th>images</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>veracity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Jack Shafer, Burgess Everett, Seung Min Kim, ...</td>\n",
       "      <td>http://www.politico.com/story/2016/09/zika-fun...</td>\n",
       "      <td>[http://static.politico.com/ae/2d/1a0119fa45b8...</td>\n",
       "      <td>http://politi.co</td>\n",
       "      <td>\"I would encourage our colleagues across the a...</td>\n",
       "      <td>McConnell punts budget vote to buy time for deal</td>\n",
       "      <td>http://politi.co/2cksDqD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Colin Taylor, Grant Stern, Brett Bose, Natali...</td>\n",
       "      <td>http://occupydemocrats.com/2016/09/21/massive-...</td>\n",
       "      <td>[http://occupydemocrats.com/wp-content/uploads...</td>\n",
       "      <td>http://occupydemocrats.com</td>\n",
       "      <td>12k SHARES SHARE THIS STORY\\n\\nMassive protest...</td>\n",
       "      <td>Massive Protests Erupt In North Carolina After...</td>\n",
       "      <td>http://occupydemocrats.com/2016/09/21/massive-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>http://rightwingnews.com/top-news/famous-dog-k...</td>\n",
       "      <td>[http://rightwingnews.com/wp-content/uploads/2...</td>\n",
       "      <td>http://rightwingnews.com</td>\n",
       "      <td>Famous dog killed in spot she waited a year fo...</td>\n",
       "      <td>Famous dog killed in spot she waited a year fo...</td>\n",
       "      <td>http://rightwingnews.com/top-news/famous-dog-k...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>The University of North Dakota is investigatin...</td>\n",
       "      <td>'Locked the black bitch out': White students u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Jack Shafer, Robert Strauss]</td>\n",
       "      <td>http://www.politico.com/magazine/story/2016/09...</td>\n",
       "      <td>[data:image/gif;base64,R0lGODlhAQABAAAAACH5BAE...</td>\n",
       "      <td>http://politi.co</td>\n",
       "      <td>As my 25th wedding anniversary approached, I t...</td>\n",
       "      <td>Worst. President. Ever.</td>\n",
       "      <td>http://politi.co/2cGdput</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             authors  \\\n",
       "0  [Jack Shafer, Burgess Everett, Seung Min Kim, ...   \n",
       "1  [Colin Taylor, Grant Stern, Brett Bose, Natali...   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4                      [Jack Shafer, Robert Strauss]   \n",
       "\n",
       "                                      canonical_link  \\\n",
       "0  http://www.politico.com/story/2016/09/zika-fun...   \n",
       "1  http://occupydemocrats.com/2016/09/21/massive-...   \n",
       "2  http://rightwingnews.com/top-news/famous-dog-k...   \n",
       "3                                                NaN   \n",
       "4  http://www.politico.com/magazine/story/2016/09...   \n",
       "\n",
       "                                              images  \\\n",
       "0  [http://static.politico.com/ae/2d/1a0119fa45b8...   \n",
       "1  [http://occupydemocrats.com/wp-content/uploads...   \n",
       "2  [http://rightwingnews.com/wp-content/uploads/2...   \n",
       "3                                                NaN   \n",
       "4  [data:image/gif;base64,R0lGODlhAQABAAAAACH5BAE...   \n",
       "\n",
       "                       source  \\\n",
       "0            http://politi.co   \n",
       "1  http://occupydemocrats.com   \n",
       "2    http://rightwingnews.com   \n",
       "3                               \n",
       "4            http://politi.co   \n",
       "\n",
       "                                                text  \\\n",
       "0  \"I would encourage our colleagues across the a...   \n",
       "1  12k SHARES SHARE THIS STORY\\n\\nMassive protest...   \n",
       "2  Famous dog killed in spot she waited a year fo...   \n",
       "3  The University of North Dakota is investigatin...   \n",
       "4  As my 25th wedding anniversary approached, I t...   \n",
       "\n",
       "                                               title  \\\n",
       "0   McConnell punts budget vote to buy time for deal   \n",
       "1  Massive Protests Erupt In North Carolina After...   \n",
       "2  Famous dog killed in spot she waited a year fo...   \n",
       "3  'Locked the black bitch out': White students u...   \n",
       "4                            Worst. President. Ever.   \n",
       "\n",
       "                                                 url  veracity  \n",
       "0                           http://politi.co/2cksDqD         1  \n",
       "1  http://occupydemocrats.com/2016/09/21/massive-...         1  \n",
       "2  http://rightwingnews.com/top-news/famous-dog-k...         1  \n",
       "3                                                NaN         1  \n",
       "4                           http://politi.co/2cGdput         1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def loadJsonFiles(directory, veracity):    \n",
    "    shouldAppend = False\n",
    "    for filename in os.listdir(directory):\n",
    "        df2 = pd.read_json(directory + filename, lines=True)\n",
    "        if (shouldAppend):\n",
    "            df = df.append(df2, ignore_index=True, sort=True)      \n",
    "        else:\n",
    "            df = df2\n",
    "        df['veracity'] = veracity\n",
    "        shouldAppend = True\n",
    "        \n",
    "            \n",
    "    # removing nan values    \n",
    "    df['source'].fillna(\"\", inplace=True)\n",
    "    for index, row in df.iterrows():\n",
    "        if (type(row['authors']) == float):\n",
    "            df.at[index, 'authors'] = []\n",
    "\n",
    "            \n",
    "    #removing unnecessary columns\n",
    "    df = df.drop(columns=['keywords','meta_data','movies', 'keywords', 'summary', 'publish_date','top_img'])\n",
    "    return df\n",
    "\n",
    "def loadDataset():\n",
    "    dataFake = loadJsonFiles('input_data/politifact/FakeNewsContent/', 0)\n",
    "    dataReal = loadJsonFiles('input_data/politifact/RealNewsContent/', 1)\n",
    "    return dataReal, dataFake\n",
    "\n",
    "dataFake, dataReal = loadDataset()\n",
    "\n",
    "dataTrainFake = dataFake[:100]\n",
    "dataTrainReal = dataReal[:100]\n",
    "dataTestFake = dataFake[101:]\n",
    "dataTestReal = dataReal[101:]\n",
    "\n",
    "dataTest = dataTestFake.append(dataTestReal,ignore_index=True, sort=True)      \n",
    "dataTrain = dataTrainFake.append(dataTrainReal,ignore_index=True, sort=True)    \n",
    "dataAll = dataFake.append(dataReal, ignore_index=True, sort=True)      \n",
    "dataAll.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Party Affiliation Model Trained - accuracy:   0.565436\n"
     ]
    }
   ],
   "source": [
    "# from ipynb.fs.full.m_partyaffiliation import PartyAffiliation\n",
    "partyAffiliation = PartyAffiliation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39560573321891\n"
     ]
    }
   ],
   "source": [
    "def DATAMINERS_getPartyAffiliationScore(headline, partyName): # return between 0 and 1, being 0 = True,  1 = Fake\n",
    "    if ( (headline == \"\") | (partyName == \"\") ):\n",
    "        return 0\n",
    "    binaryValue, probValue = partyAffiliation.predict(headline, partyName)\n",
    "    return (1 - float(probValue))\n",
    "\n",
    "print(DATAMINERS_getPartyAffiliationScore(\"Says the Annies List political group supports third-trimester abortions on demand\", \"republican\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature 5: Click Bait "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Clickbait():\n",
    "    \n",
    "    question_words = ['who', 'whos', 'whose', 'what', 'whats', 'whatre', 'when', 'whenre', 'whens', 'couldnt',\n",
    "            'where', 'wheres', 'whered', 'why', 'whys', 'can', 'cant', 'could', 'will', 'would', 'is',\n",
    "            'isnt', 'should', 'shouldnt', 'you', 'your', 'youre', 'youll', 'youd', 'here', 'heres',\n",
    "            'how', 'hows', 'howd', 'this', 'are', 'arent', 'which', 'does', 'doesnt']\n",
    "\n",
    "    contractions = ['tis', 'aint', 'amnt', 'arent', 'cant', 'couldve', 'couldnt', 'couldntve',\n",
    "                    'didnt', 'doesnt', 'dont', 'gonna', 'gotta', 'hadnt', 'hadntve', 'hasnt',\n",
    "                    'havent', 'hed', 'hednt', 'hedve', 'hell', 'hes', 'hesnt', 'howd', 'howll',\n",
    "                    'hows', 'id', 'idnt', 'idntve', 'idve', 'ill', 'im', 'ive', 'ivent', 'isnt',\n",
    "                    'itd', 'itdnt', 'itdntve', 'itdve', 'itll', 'its', 'itsnt', 'mightnt',\n",
    "                    'mightve', 'mustnt', 'mustntve', 'mustve', 'neednt', 'oclock', 'ol', 'oughtnt',\n",
    "                    'shant', 'shed', 'shednt', 'shedntve', 'shedve', 'shell', 'shes', 'shouldve',\n",
    "                    'shouldnt', 'shouldntve', 'somebodydve', 'somebodydntve', 'somebodys',\n",
    "                    'someoned', 'someonednt', 'someonedntve', 'someonedve', 'someonell', 'someones',\n",
    "                    'somethingd', 'somethingdnt', 'somethingdntve', 'somethingdve', 'somethingll',\n",
    "                    'somethings', 'thatll', 'thats', 'thatd', 'thered', 'therednt', 'theredntve',\n",
    "                    'theredve', 'therere', 'theres', 'theyd', 'theydnt', 'theydntve', 'theydve',\n",
    "                    'theydvent', 'theyll', 'theyontve', 'theyre', 'theyve', 'theyvent', 'wasnt',\n",
    "                    'wed', 'wedve', 'wednt', 'wedntve', 'well', 'wontve', 'were', 'weve', 'werent',\n",
    "                    'whatd', 'whatll', 'whatre', 'whats', 'whatve', 'whens', 'whered', 'wheres',\n",
    "                    'whereve', 'whod', 'whodve', 'wholl', 'whore', 'whos', 'whove', 'whyd', 'whyre',\n",
    "                    'whys', 'wont', 'wontve', 'wouldve', 'wouldnt', 'wouldntve', 'yall', 'yalldve',\n",
    "                    'yalldntve', 'yallll', 'yallont', 'yallllve', 'yallre', 'yallllvent', 'yaint',\n",
    "                    'youd', 'youdve', 'youll', 'youre', 'yourent', 'youve', 'youvent']\n",
    "    \n",
    "    def process_text(self, text):\n",
    "        result = text.replace('/', '').replace('\\n', '')\n",
    "        result = re.sub(r'[1-9]+', 'number', result)\n",
    "        result = re.sub(r'(\\w)(\\1{2,})', r'\\1', result)\n",
    "        result = re.sub(r'(?x)\\b(?=\\w*\\d)\\w+\\s*', '', result)\n",
    "        result = ''.join(t for t in result if t not in punctuation)\n",
    "        result = re.sub(r' +', ' ', result).lower().strip()\n",
    "        return result\n",
    "    \n",
    "    def cnt_stop_words(self, text):\n",
    "        s = text.split()\n",
    "        num = len([word for word in s if word in self.stop])\n",
    "        return num\n",
    "\n",
    "    def num_contract(self, text):\n",
    "        s = text.split()\n",
    "        num = len([word for word in s if word in self.contractions])\n",
    "        return num\n",
    "\n",
    "    def question_word(self, text):\n",
    "        s = text.split()\n",
    "        if s[0] in self.question_words:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def part_of_speech(self, text):\n",
    "        s = text.split()\n",
    "        nonstop = [word for word in s if word not in self.stop]\n",
    "        pos = [part[1] for part in nltk.pos_tag(nonstop)]\n",
    "        pos = ' '.join(pos)\n",
    "        return pos\n",
    "\n",
    "\n",
    "    def __init__(self):        \n",
    "        df_ycb = pd.read_csv('input_data/clickbait/clickbait_data.txt', sep=\"\\n\", header=None, names=['text'])\n",
    "        df_ycb['clickbait'] = 1\n",
    "\n",
    "        df_ncb = pd.read_csv('input_data/clickbait/non_clickbait_data.txt', sep=\"\\n\", header=None, names=['text'])\n",
    "        df_ncb['clickbait'] = 0\n",
    "\n",
    "        df = df_ycb.append(df_ncb, ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "        \n",
    "\n",
    "       \n",
    "        self.stop = stopwords.words('english')\n",
    "       \n",
    "        # Creating some latent variables from the data\n",
    "        df['text']     = df['text'].apply(self.process_text)\n",
    "        df['question'] = df['text'].apply(self.question_word)\n",
    "\n",
    "        df['num_words']       = df['text'].apply(lambda x: len(x.split()))\n",
    "        df['part_speech']     = df['text'].apply(self.part_of_speech)\n",
    "        df['num_contract']    = df['text'].apply(self.num_contract)\n",
    "        df['num_stop_words']  = df['text'].apply(self.cnt_stop_words)\n",
    "        df['stop_word_ratio'] = df['num_stop_words']/df['num_words']\n",
    "        df['contract_ratio']  = df['num_contract']/df['num_words']\n",
    "\n",
    "        \n",
    "        df.drop(['num_stop_words','num_contract'], axis=1, inplace=True)\n",
    "\n",
    "        df_train, df_test = train_test_split(df, test_size=0.2, random_state=0)\n",
    "\n",
    "        self.tfidf = TfidfVectorizer(min_df=3, max_features=None, strip_accents='unicode',\n",
    "                                   analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1,5),\n",
    "                                   use_idf=1, smooth_idf=1, sublinear_tf=1)\n",
    "\n",
    "        X_train_text = self.tfidf.fit_transform(df_train['text'])\n",
    "        X_test_text  = self.tfidf.transform(df_test['text'])\n",
    "\n",
    "        self.cvec = CountVectorizer()\n",
    "\n",
    "        X_train_pos = self.cvec.fit_transform(df_train['part_speech'])\n",
    "        X_test_pos  = self.cvec.transform(df_test['part_speech'])\n",
    "\n",
    "        self.scNoMean = StandardScaler(with_mean=False)  # we pass with_mean=False to preserve the sparse matrix\n",
    "        X_train_pos_sc = self.scNoMean.fit_transform(X_train_pos)\n",
    "        X_test_pos_sc  = self.scNoMean.transform(X_test_pos)\n",
    "\n",
    "        X_train_val = df_train.drop(['clickbait','text','part_speech'], axis=1).values\n",
    "        X_test_val  = df_test.drop(['clickbait','text','part_speech'], axis=1).values\n",
    "\n",
    "        self.sc = StandardScaler()\n",
    "        X_train_val_sc = self.sc.fit(X_train_val).transform(X_train_val)\n",
    "        X_test_val_sc  = self.sc.transform(X_test_val)\n",
    "\n",
    "        y_train = df_train['clickbait'].values\n",
    "        y_test  = df_test['clickbait'].values\n",
    "\n",
    "\n",
    "\n",
    "        X_train = sparse.hstack([X_train_val_sc, X_train_text, X_train_pos_sc]).tocsr()\n",
    "        X_test  = sparse.hstack([X_test_val_sc, X_test_text, X_test_pos_sc]).tocsr()\n",
    "\n",
    "        self.model = LogisticRegression(penalty='l2', C=98.94736842105263)\n",
    "        self.model = self.model.fit(X_train, y_train)\n",
    "        \n",
    "        predicted_LogR = self.model.predict(X_test)\n",
    "        score = metrics.accuracy_score(y_test, predicted_LogR)\n",
    "        print(\"Clickbait Model Trained - accuracy:   %0.6f\" % score)\n",
    "\n",
    "#     predict = model.predict(X_test)\n",
    "#     print(classification_report(y_test, predict))\n",
    "\n",
    "\n",
    "    def predict(self, text):\n",
    "        #creating the dataframe with our text so we can leverage the existing code\n",
    "        dfrme = pd.DataFrame(index=[0], columns=['text'])\n",
    "        dfrme['text'] = text\n",
    "\n",
    "        #processing text\n",
    "        dfrme['text']     = dfrme['text'].apply(self.process_text)\n",
    "\n",
    "        #adding latent variables\n",
    "        dfrme['question'] = dfrme['text'].apply(self.question_word)\n",
    "        dfrme['num_words']       = dfrme['text'].apply(lambda x: len(x.split()))\n",
    "        dfrme['part_speech']     = dfrme['text'].apply(self.part_of_speech)\n",
    "        dfrme['num_contract']    = dfrme['text'].apply(self.num_contract)\n",
    "        dfrme['num_stop_words']  = dfrme['text'].apply(self.cnt_stop_words)\n",
    "        dfrme['stop_word_ratio'] = dfrme['num_stop_words']/dfrme['num_words']\n",
    "        dfrme['contract_ratio']  = dfrme['num_contract']/dfrme['num_words']\n",
    "\n",
    "        #removing latent variables that have high colinearity with other features\n",
    "        dfrme.drop(['num_stop_words','num_contract'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "        Xtxt_val  = dfrme.drop(['text','part_speech'], axis=1).values\n",
    "        Xtxt_val_sc  = self.sc.transform(Xtxt_val)\n",
    "\n",
    "        Xtxt_text  = self.tfidf.transform(dfrme['text'])\n",
    "\n",
    "        Xtxt_pos  = self.cvec.transform(dfrme['part_speech'])\n",
    "        Xtxt_pos_sc  = self.scNoMean.transform(Xtxt_pos)\n",
    "        Xtxt  = sparse.hstack([Xtxt_val_sc, Xtxt_text, Xtxt_pos_sc]).tocsr()\n",
    "\n",
    "        predicted = self.model.predict(Xtxt)\n",
    "        predicedProb = self.model.predict_proba(Xtxt)[:,1]\n",
    "        return predicted, predicedProb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clickbait Model Trained - accuracy:   0.976875\n"
     ]
    }
   ],
   "source": [
    "# from ipynb.fs.full.m_clickbait import Clickbait\n",
    "clickBait = Clickbait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9985146734984097\n"
     ]
    }
   ],
   "source": [
    "def DATAMINERS_getClickbaitScore(headline): # return between 0 and 1, being 0 = True,  1 = Fake\n",
    "    if (headline == \"\"):\n",
    "        return 0\n",
    "    binaryValue, probValue = clickBait.predict(headline)\n",
    "    return float(probValue)\n",
    "\n",
    "print(DATAMINERS_getClickbaitScore(\"Should You bring the money now\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature 6 : Spam Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to simplify label classes\n",
    "\n",
    "* Original --\tTrue\n",
    "* True\t--\tTrue\n",
    "* Mostly-true\t-- True\n",
    "* Half-true\t-- True\n",
    "* Barely-true\t-- False\n",
    "* False\t-- False\n",
    "* Pants-fire\t-- False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'input_data/train_sensational_feature.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-69884866c438>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mspamscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpamScoreFeature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0mspamscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Says the Annies List political group supports third-trimester abortions on demand.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-69884866c438>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m#load the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mcolumnNames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"encoded_label\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"headline_text\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sensational_vector\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mdataTrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input_data/train_sensational_feature.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumnNames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mdataTest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input_data/test_sensational_feature.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumnNames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mdataTrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'input_data/train_sensational_feature.csv' does not exist"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "class SpamScoreFeature():\n",
    "    def __init__(self): \n",
    "        #load the dataset\n",
    "        columnNames = [\"encoded_label\", \"headline_text\", \"sensational_vector\"]\n",
    "        dataTrain = pd.read_csv('input_data/train_sensational_feature.csv', sep=',', header=None, names = columnNames)\n",
    "        dataTest = pd.read_csv('input_data/test_sensational_feature.csv', sep=',', header=None, names = columnNames)\n",
    "        dataTrain = dataTrain.loc[1:]\n",
    "        dataTest = dataTest.loc[1:]\n",
    "        \n",
    "        #load the spam dictionary\n",
    "        spam_dict = pd.read_csv('input_data/spam/spam_dict.csv', usecols= [1], names = ['spamword'], encoding='latin-1', error_bad_lines=False)\n",
    "        spam_dict = spam_dict.fillna(0)\n",
    "        spam_dict = spam_dict.iloc[1:]\n",
    "        spam_dict = spam_dict.drop_duplicates()\n",
    "\n",
    "        # spam_dict.head(5)\n",
    "        #Count vector for train data\n",
    "        spamcountV = CountVectorizer(vocabulary=list(set(spam_dict['spamword'])))\n",
    "        train_count = spamcountV.fit_transform(dataTrain['headline_text'])\n",
    "       \n",
    "   \n",
    "        self.logR_pipeline = Pipeline([\n",
    "            ('NBCV',spamcountV),\n",
    "            ('nb_clf',MultinomialNB())])\n",
    "\n",
    "        self.logR_pipeline.fit(dataTrain['headline_text'], dataTrain['encoded_label'])\n",
    "        predicted_LogR = self.logR_pipeline.predict(dataTest['headline_text'])\n",
    "        score = metrics.accuracy_score(dataTest['encoded_label'], predicted_LogR)\n",
    "        print(\"Spam Score Model Trained - accuracy:   %0.6f\" % score)\n",
    "        \n",
    "\n",
    "    def predict(self, text):\n",
    "        predicted = self.logR_pipeline.predict([text])\n",
    "        predicedProb = self.logR_pipeline.predict_proba([text])[:,1]\n",
    "        return bool(predicted), float(predicedProb)\n",
    "    \n",
    "    \n",
    "spamscore = SpamScoreFeature()\n",
    "spamscore.predict(\"Says the Annies List political group supports third-trimester abortions on demand.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spamscore' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-b74a7c7f5018>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATAMINERS_getSpamScore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Says the Annies List political group supports third-trimester abortions on demand.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-b74a7c7f5018>\u001b[0m in \u001b[0;36mDATAMINERS_getSpamScore\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mDATAMINERS_getSpamScore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# return between 0 and 1, being 0 = True,  1 = Fake\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#print(clickBait.predict(\"Should You bring the money now\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mbinaryValue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobValue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspamscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spamscore' is not defined"
     ]
    }
   ],
   "source": [
    "def DATAMINERS_getSpamScore(text):  # return between 0 and 1, being 0 = True,  1 = Fake\n",
    "    #print(clickBait.predict(\"Should You bring the money now\"))\n",
    "    binaryValue, probValue = spamscore.predict(text)\n",
    "    return (float(probValue))\n",
    "\n",
    "print(DATAMINERS_getSpamScore(\"Says the Annies List political group supports third-trimester abortions on demand.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the input data files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature 7 : Author Credibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trueZeroAuthors= 13\n",
      "fakeZeroAuthors= 85\n",
      "trueOneAuthors= 36\n",
      "fakeOneAuthors= 24\n",
      "trueMoreThanOneAuthors= 71\n",
      "fakeMoreThanOneAuthors= 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>veracity</th>\n",
       "      <th>authors_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   veracity  authors_count\n",
       "0         1            4.0\n",
       "1         1            4.0\n",
       "2         1            0.0\n",
       "3         1            0.0\n",
       "4         1            2.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataAllAuthorsVeracity = dataAll.copy()\n",
    "\n",
    "fakeZero = 0\n",
    "fakeOne = 0\n",
    "falseMoreThanOne = 0\n",
    "trueZero = 0\n",
    "trueOne = 0\n",
    "trueMoreThanOne = 0\n",
    "for index, row in dataAllAuthorsVeracity.iterrows():\n",
    "    authorsCount = len(row['authors'])\n",
    "    dataAllAuthorsVeracity.at[index, 'authors_count'] = len(row['authors'])\n",
    "    if (authorsCount == 0):\n",
    "        if (row['veracity'] == 1):\n",
    "            trueZero += 1\n",
    "        else:\n",
    "            fakeZero += 1\n",
    "    elif (authorsCount == 1):\n",
    "        if (row['veracity'] == 1):\n",
    "            trueOne += 1\n",
    "        else:\n",
    "            fakeOne += 1\n",
    "    elif (authorsCount > 1):\n",
    "        if (row['veracity'] == 1):\n",
    "            trueMoreThanOne += 1\n",
    "        else:\n",
    "            falseMoreThanOne += 1\n",
    "\n",
    "print(\"trueZeroAuthors=\", trueZero)\n",
    "print(\"fakeZeroAuthors=\", fakeZero)\n",
    "print(\"trueOneAuthors=\", trueOne)\n",
    "print(\"fakeOneAuthors=\", fakeOne)\n",
    "print(\"trueMoreThanOneAuthors=\", trueMoreThanOne)\n",
    "print(\"fakeMoreThanOneAuthors=\", falseMoreThanOne)\n",
    "\n",
    "columnsToRemove = ['authors', 'canonical_link', 'images', 'source','url', 'text', 'title']\n",
    "dataAllAuthorsVeracity = dataAllAuthorsVeracity.drop(columns=columnsToRemove)\n",
    "dataAllAuthorsVeracity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTrainAuthorsVeracity = dataTrain.copy()\n",
    "dataTestAuthorsVeracity = dataTest.copy()\n",
    "\n",
    "for index, row in dataTrainAuthorsVeracity.iterrows():\n",
    "    dataTrainAuthorsVeracity.at[index, 'authors_count'] = len(row['authors'])\n",
    "\n",
    "for index, row in dataTestAuthorsVeracity.iterrows():\n",
    "    dataTestAuthorsVeracity.at[index, 'authors_count'] = len(row['authors'])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy= 0.8421052631578947\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "X_train = dataTrainAuthorsVeracity['authors_count'].values.reshape(-1, 1)\n",
    "Y_train = dataTrainAuthorsVeracity['veracity'].values\n",
    "X_test = dataTestAuthorsVeracity['authors_count'].values.reshape(-1, 1)\n",
    "Y_test = dataTestAuthorsVeracity['veracity'].values.reshape(-1, 1)\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "logClassifierAuthorsCount = linear_model.LogisticRegression(solver='liblinear', C=1, random_state=111)\n",
    "logClassifierAuthorsCount.fit(X_train, Y_train)\n",
    "predicted = logClassifierAuthorsCount.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"accuracy=\", metrics.accuracy_score(Y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015660137851400635\n"
     ]
    }
   ],
   "source": [
    "def DATAMINERS_getAuthorScore(numAuthors): # return between 0 and 1, being 0 = True,  1 = Fake\n",
    "    x = np.array(numAuthors).reshape(-1, 1)\n",
    "    predicted = logClassifierAuthorsCount.predict(x)\n",
    "    predicedProbTrue = logClassifierAuthorsCount.predict_proba(x)[:,1]\n",
    "    #return int(predicted), float(predicedProb)\n",
    "    return 1 - float(predicedProbTrue)\n",
    "\n",
    "print(DATAMINERS_getAuthorScore(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature 8 : Source Reputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site name</th>\n",
       "      <th>type of site</th>\n",
       "      <th>registration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16wmpo.com</td>\n",
       "      <td>imposter site</td>\n",
       "      <td>scottsdale, ariz. **</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24online.news</td>\n",
       "      <td>imposter site</td>\n",
       "      <td>panama, pa. **</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24wpn.com</td>\n",
       "      <td>fake news</td>\n",
       "      <td>veles, macedonia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24x365live.com</td>\n",
       "      <td>fake news</td>\n",
       "      <td>kobenhavn, denmark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>247newsmedia.com</td>\n",
       "      <td>fake news</td>\n",
       "      <td>kumanovo, macedonia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          site name   type of site          registration\n",
       "0        16wmpo.com  imposter site  scottsdale, ariz. **\n",
       "1     24online.news  imposter site        panama, pa. **\n",
       "2         24wpn.com      fake news      veles, macedonia\n",
       "3    24x365live.com      fake news   kobenhavn, denmark \n",
       "4  247newsmedia.com      fake news   kumanovo, macedonia"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataFakeNewsSites = pd.read_csv(\"input_data/politifact-fakenews-sites.csv\")\n",
    "dataFakeNewsSites.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['imposter site', 'fake news', 'parody site', 'some fake stories'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFakeNewsSites['type of site'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the sources are classified in different categories. Almost are all fake (fake news, parody,..) except the category 'some fake stories'. So let's hot encode those categories as 1 for fake news and 0.5 for some fake news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site name</th>\n",
       "      <th>type of site</th>\n",
       "      <th>registration</th>\n",
       "      <th>fake_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16wmpo.com</td>\n",
       "      <td>imposter site</td>\n",
       "      <td>scottsdale, ariz. **</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24online.news</td>\n",
       "      <td>imposter site</td>\n",
       "      <td>panama, pa. **</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24wpn.com</td>\n",
       "      <td>fake news</td>\n",
       "      <td>veles, macedonia</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24x365live.com</td>\n",
       "      <td>fake news</td>\n",
       "      <td>kobenhavn, denmark</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>247newsmedia.com</td>\n",
       "      <td>fake news</td>\n",
       "      <td>kumanovo, macedonia</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          site name   type of site          registration  fake_score\n",
       "0        16wmpo.com  imposter site  scottsdale, ariz. **         1.0\n",
       "1     24online.news  imposter site        panama, pa. **         1.0\n",
       "2         24wpn.com      fake news      veles, macedonia         1.0\n",
       "3    24x365live.com      fake news   kobenhavn, denmark          1.0\n",
       "4  247newsmedia.com      fake news   kumanovo, macedonia         1.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index, row in dataFakeNewsSites.iterrows():\n",
    "    score = 1\n",
    "    if (row['type of site'] == 'some fake stories'):\n",
    "        score = 0.5\n",
    "    dataFakeNewsSites.at[index, 'fake_score'] = score\n",
    "\n",
    "dataFakeNewsSites.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def DATAMINERS_getSourceReputationScore(source): # return between 0 and 1, being 0 = True,  1 = Fake\n",
    "    if (source == \"\"):\n",
    "        return 0\n",
    "    d = dataFakeNewsSites[dataFakeNewsSites['site name'].str.match(source)]\n",
    "    if (d['fake_score'].empty):\n",
    "        return 0\n",
    "    return int(d['fake_score'].values)\n",
    "\n",
    "\n",
    "DATAMINERS_getSourceReputationScore('24wpn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature 9 : Content Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model slope:     2.8672921260228005e-05\n",
      "Model intercept: 0.41180985978637996\n",
      "R2 score: 0.04612397796223433\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataAllBodyLength = dataAll.copy()\n",
    "for index, row in dataAllBodyLength.iterrows():\n",
    "    textLength = len(row['text'])\n",
    "    dataAllBodyLength.at[index, 'text_length'] = textLength\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linearRegressionBodyLength = LinearRegression(fit_intercept=True)\n",
    "\n",
    "A = np.array(list(dataAllBodyLength.text_length))\n",
    "B = np.array(list(dataAllBodyLength.veracity))\n",
    "\n",
    "linearRegressionBodyLength.fit(A[:, np.newaxis], B)\n",
    "\n",
    "xfit = np.linspace(-1, max(dataAllBodyLength.text_length), 1000)\n",
    "yfit = linearRegressionBodyLength.predict(xfit[:, np.newaxis])\n",
    "\n",
    "plt.scatter(A, B, s=1, c=\"orange\")\n",
    "plt.plot(xfit, yfit);\n",
    "\n",
    "print(\"Model slope:    \", linearRegressionBodyLength.coef_[0])\n",
    "print(\"Model intercept:\", linearRegressionBodyLength.intercept_)\n",
    "print(\"R2 score:\", linearRegressionBodyLength.score(A[:, np.newaxis], B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7105263157894737\n"
     ]
    }
   ],
   "source": [
    "for index, row in dataTrain.iterrows():\n",
    "    textLength = len(row['text'])\n",
    "    dataTrain.at[index, 'text_length'] = textLength\n",
    "\n",
    "for index, row in dataTest.iterrows():\n",
    "    textLength = len(row['text'])\n",
    "    dataTest.at[index, 'text_length'] = textLength\n",
    "\n",
    "from sklearn import linear_model\n",
    "# from sklearn import linear_model\n",
    "\n",
    "logClassifierBodyLength = linear_model.LogisticRegression(solver='liblinear', C=17/1000, random_state=111)\n",
    "logClassifierBodyLength.fit(dataTrain['text_length'].values.reshape(-1, 1), dataTrain['veracity'].values)\n",
    "\n",
    "predicted = logClassifierBodyLength.predict(dataTest['text_length'].values.reshape(-1, 1))\n",
    "\n",
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(dataTest['veracity'].values.reshape(-1, 1), predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20395870093748913\n"
     ]
    }
   ],
   "source": [
    "def DATAMINERS_getBodyLengthScore(length): # return between 0 and 1, being 0 = True,  1 = Fake\n",
    "    x = np.array(length).reshape(-1, 1)\n",
    "    predicted = logClassifierBodyLength.predict(x)\n",
    "    predicedProb = logClassifierBodyLength.predict_proba(x)[:,1]\n",
    "    #return int(predicted), float(predicedProb)\n",
    "    return 1 - float(predicedProb)\n",
    "\n",
    "print(DATAMINERS_getBodyLengthScore(12000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature 10 : Word Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import  LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.porter import *\n",
    "from sklearn import metrics\n",
    "\n",
    "class WordFrequency():\n",
    "\n",
    "    def __init__(self):        \n",
    "\n",
    "        columnNames = [\"id\", \"label\", \"statement\", \"subject\", \"speaker\", \"speaker_job_title\", \"state_info\", \"party_affiliation\", \"barely_true_counts\", \"false_counts\", \"half_true_counts\", \"mostly_true_counts\", \"pants_on_fire_counts\", \"context\"]\n",
    "        dataTrain = pd.read_csv('input_data/dataset/train.tsv', sep='\\t', header=None, names = columnNames)\n",
    "        dataValidate = pd.read_csv('input_data/dataset/valid.tsv', sep='\\t', header=None, names = columnNames)\n",
    "        dataTest = pd.read_csv('input_data/dataset/test.tsv', sep='\\t', header=None, names = columnNames)\n",
    "        \n",
    "        #dropping columns\n",
    "        columnsToRemove = ['id','subject', 'speaker', 'context','speaker_job_title', 'state_info', 'party_affiliation', 'barely_true_counts', 'false_counts', 'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts']\n",
    "        dataTrain = dataTrain.drop(columns=columnsToRemove)\n",
    "        dataValidate = dataValidate.drop(columns=columnsToRemove)\n",
    "        dataTest = dataTest.drop(columns=columnsToRemove)\n",
    "\n",
    "        def convertMulticlassToBinaryclass(r):\n",
    "            v = r['label']\n",
    "            if (v == 'true'):\n",
    "                return 'true'\n",
    "            if (v == 'mostly-true'):\n",
    "                return 'true'\n",
    "            if (v == 'half-true'):\n",
    "                return 'true'\n",
    "            if (v == 'barely-true'):\n",
    "                return 'false'\n",
    "            if (v == 'false'):\n",
    "                return 'false'\n",
    "            if (v == 'pants-fire'):\n",
    "                return 'false'\n",
    "        dataTrain['label'] = dataTrain.apply(convertMulticlassToBinaryclass, axis=1)\n",
    "        dataValidate['label'] = dataValidate.apply(convertMulticlassToBinaryclass, axis=1)\n",
    "        dataTest['label'] = dataTest.apply(convertMulticlassToBinaryclass, axis=1)\n",
    "        \n",
    "\n",
    "    \n",
    "        tfidfV = TfidfVectorizer(stop_words='english', min_df=5, max_df=30, use_idf=True, smooth_idf=True, token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b')\n",
    "        train_tfidf = tfidfV.fit_transform(dataTrain['statement'].values)\n",
    "        test_tfidf = tfidfV.fit_transform(dataTest['statement'].values)\n",
    "\n",
    "#         print('TF-IDF VECTORIZER')\n",
    "\n",
    "        ## Removing plurals for the tokens using PorterStemmer\n",
    "        stemmer = PorterStemmer()\n",
    "        tfidfVPlurals= tfidfV.get_feature_names()\n",
    "        tfidfVSingles= [stemmer.stem(plural) for plural in tfidfVPlurals]\n",
    "\n",
    "        # Applying Set to remove duplicates\n",
    "        tfidfVTokens = list(set(tfidfVSingles))\n",
    "#         print('TFIDFV Tokens')\n",
    "#         print(tfidfVTokens)\n",
    "\n",
    "        self.logR_pipeline = Pipeline([\n",
    "                ('LogRCV', tfidfV),\n",
    "                ('LogR_clf',LogisticRegression(solver='liblinear', C=32/100))\n",
    "                ])\n",
    "\n",
    "        self.logR_pipeline.fit(dataTrain['statement'],dataTrain['label'])\n",
    "        predicted_LogR = self.logR_pipeline.predict(dataTest['statement'])\n",
    "        score = metrics.accuracy_score(dataTest['label'], predicted_LogR)\n",
    "        print(\"Word Frequency Model Trained - accuracy:   %0.6f\" % score)\n",
    "        \n",
    "\n",
    "    def predict(self, text):\n",
    "        predicted = self.logR_pipeline.predict([text])\n",
    "        predicedProb = self.logR_pipeline.predict_proba([text])[:,1]\n",
    "        return bool(predicted), float(predicedProb)\n",
    "    \n",
    "    \n",
    "# wf = WordFrequency()\n",
    "# wf.predict(\"Says the Annies List political group supports third-trimester abortions on demand.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Frequency Model Trained - accuracy:   0.599053\n"
     ]
    }
   ],
   "source": [
    "# from ipynb.fs.full.m_wordfrequency import WordFrequency\n",
    "wordFrequency = WordFrequency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5104703891221563\n"
     ]
    }
   ],
   "source": [
    "def DATAMINERS_getWordFrequencyScore(text):  # return between 0 and 1, being 0 = True,  1 = Fake\n",
    "    #print(clickBait.predict(\"Should You bring the money now\"))\n",
    "    binaryValue, probValue = wordFrequency.predict(text)\n",
    "    return (1 - float(probValue))\n",
    "\n",
    "print(DATAMINERS_getWordFrequencyScore(\"Says the Annies List political group supports third-trimester abortions on demand.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency Heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import  LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem.porter import *\n",
    "from sklearn import metrics\n",
    "\n",
    "class WordFrequency():\n",
    "\n",
    "    def __init__(self):        \n",
    "\n",
    "        columnNames = [\"id\", \"label\", \"statement\", \"subject\", \"speaker\", \"speaker_job_title\", \"state_info\", \"party_affiliation\", \"barely_true_counts\", \"false_counts\", \"half_true_counts\", \"mostly_true_counts\", \"pants_on_fire_counts\", \"context\"]\n",
    "        dataTrain = pd.read_csv('input_data/dataset/train.tsv', sep='\\t', header=None, names = columnNames)\n",
    "        dataValidate = pd.read_csv('input_data/dataset/valid.tsv', sep='\\t', header=None, names = columnNames)\n",
    "        dataTest = pd.read_csv('input_data/dataset/test.tsv', sep='\\t', header=None, names = columnNames)\n",
    "        \n",
    "        #dropping columns\n",
    "        columnsToRemove = ['id','subject', 'speaker', 'context','speaker_job_title', 'state_info', 'party_affiliation', 'barely_true_counts', 'false_counts', 'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts']\n",
    "        dataTrain = dataTrain.drop(columns=columnsToRemove)\n",
    "        dataValidate = dataValidate.drop(columns=columnsToRemove)\n",
    "        dataTest = dataTest.drop(columns=columnsToRemove)\n",
    "\n",
    "        def convertMulticlassToBinaryclass(r):\n",
    "            v = r['label']\n",
    "            if (v == 'true'):\n",
    "                return 'true'\n",
    "            if (v == 'mostly-true'):\n",
    "                return 'true'\n",
    "            if (v == 'half-true'):\n",
    "                return 'true'\n",
    "            if (v == 'barely-true'):\n",
    "                return 'false'\n",
    "            if (v == 'false'):\n",
    "                return 'false'\n",
    "            if (v == 'pants-fire'):\n",
    "                return 'false'\n",
    "        dataTrain['label'] = dataTrain.apply(convertMulticlassToBinaryclass, axis=1)\n",
    "        dataValidate['label'] = dataValidate.apply(convertMulticlassToBinaryclass, axis=1)\n",
    "        dataTest['label'] = dataTest.apply(convertMulticlassToBinaryclass, axis=1)\n",
    "        \n",
    "\n",
    "    \n",
    "        vectorizer = CountVectorizer()\n",
    "        train_tfidf = vectorizer.fit(dataTrain['statement'].values)\n",
    "        test_tfidf =  vectorizer.fit(dataTest['statement'].values)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        ## Removing plurals for the tokens using PorterStemmer\n",
    "        stemmer = PorterStemmer()\n",
    "        countPlurals = vectorizer.get_feature_names()\n",
    "        countSingles = [stemmer.stem(plural) for plural in countPlurals]\n",
    "\n",
    "        # Applying Set to remove duplicates\n",
    "        countTokens = list(set(countSingles))\n",
    "#         print('TFIDFV Tokens')\n",
    "#         print(tfidfVTokens)\n",
    "\n",
    "        self.logR_pipeline = Pipeline([\n",
    "                ('LogRCV', vectorizer),\n",
    "                ('LogR_clf',LogisticRegression(solver='liblinear', C=32/100))\n",
    "                ])\n",
    "\n",
    "        self.logR_pipeline.fit(dataTrain['statement'],dataTrain['label'])\n",
    "        predicted_LogR = self.logR_pipeline.predict(dataTest['statement'])\n",
    "        score = metrics.accuracy_score(dataTest['label'], predicted_LogR)\n",
    "        print(\"Word Frequency Model Trained - accuracy:   %0.6f\" % score)\n",
    "        \n",
    "\n",
    "    def predict(self, text):\n",
    "        predicted = self.logR_pipeline.predict([text])\n",
    "        predicedProb = self.logR_pipeline.predict_proba([text])[:,1]\n",
    "        return bool(predicted), float(predicedProb)\n",
    "    \n",
    "    \n",
    "# wf = WordFrequency()\n",
    "# wf.predict(\"Says the Annies List political group supports third-trimester abortions on demand.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Frequency Model Trained - accuracy:   0.614049\n"
     ]
    }
   ],
   "source": [
    "wordFrequency = WordFrequency()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL COMBINED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "def isFakeNews(text, headline=\"\", numAuthors = 0, source = \"\", party =\"\"):\n",
    "    accur = [0.84, 0.56, 0.95, 0.35,  0.1 ,0.54, 0.98, 0.71, 0.6, 1] # using the (normalized) accuracy as weigths\n",
    "    w = [float(i)/sum(accur) for i in accur]\n",
    "    sumW = 0\n",
    "    prob = []\n",
    "    prob.append(w[0] * DATAMINERS_getAuthorScore(numAuthors))\n",
    "    sumW += w[0]\n",
    "    if ( (headline != \"\") & (party != \"\")):\n",
    "        prob.append(w[1] * DATAMINERS_getPartyAffiliationScore(headline, party))\n",
    "        sumW += w[1]\n",
    "    if (headline != \"\"):\n",
    "        prob.append(w[2] * DATAMINERS_getClickbaitScore(headline))\n",
    "        sumW += w[2]\n",
    "    if (headline != \"\"):\n",
    "        prob.append(w[3] * DATAMINERS_getSentimentAnalysisScore(headline))\n",
    "        sumW += w[3]\n",
    "    if (headline != \"\"):\n",
    "        prob.append(w[4] * DATAMINERS_getLDATopicModellingScore(headline))\n",
    "        sumW += w[4]\n",
    "    if (headline != \"\"):\n",
    "        prob.append(w[5] * DATAMINERS_getSensationalismScore(headline))\n",
    "        sumW += w[5]\n",
    "    if (headline != \"\"):\n",
    "        prob.append(w[6] * DATAMINERS_getSpamScore(headline))\n",
    "        sumW += w[6]\n",
    "    prob.append(w[7] * DATAMINERS_getBodyLengthScore(len(text)))\n",
    "    sumW += w[7]\n",
    "    prob.append(w[8] * DATAMINERS_getWordFrequencyScore(text))\n",
    "    sumW += w[8]\n",
    "    if (party != \"\"):\n",
    "        prob.append(w[9] * DATAMINERS_getSourceReputationScore(source))\n",
    "        sumW += w[9]\n",
    "    \n",
    "    probTotal = sum(prob[0:len(prob)]) / sumW\n",
    "    return probTotal\n",
    "    \n",
    "result = isFakeNews(\"Yesterday, the Brazilian soccer team won the world cup by defeating Argentina\", \"World Cup ends\", 1, \"cnn.com\", \"republican\")\n",
    "\n",
    "if result > 0.5:\n",
    "    print(\"is FAKE NEWS!!!\")\n",
    "else:\n",
    "    print(\"it is NOT fake news!!!\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "truePos = 0\n",
    "trueNeg = 0\n",
    "falsePos = 0\n",
    "falseNeg = 0\n",
    "for index, row in dataTest.iterrows():\n",
    "    text = row['text']\n",
    "    headline= row['title']\n",
    "    numAuthors = len(row['authors'])\n",
    "    source = row['source']\n",
    "    party = \"\"\n",
    "    if 'party' in dataTest.columns:\n",
    "        party = row['party']\n",
    "    pred = isFakeNews(text, headline, numAuthors, source, party)\n",
    "    if ((row['veracity'] == 1) &  (pred < 0.5) ):\n",
    "        truePos += 1\n",
    "    elif ((row['veracity'] == 0) & (pred >= 0.5) ):\n",
    "        trueNeg += 1\n",
    "    elif ((row['veracity'] == 1) &  (pred >= 0.5) ):\n",
    "        falsePos += 1            \n",
    "    elif ((row['veracity'] == 0) &  (pred < 0.5) ):\n",
    "        falseNeg += 1\n",
    "        \n",
    "print(\"truePos=\", truePos)\n",
    "print(\"trueNeg=\", trueNeg)\n",
    "print(\"falsePos=\", falsePos)\n",
    "print(\"falseNeg=\", falseNeg)\n",
    "print(\"accuracy=\", (truePos/(truePos+falseNeg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we add some error margin, let's say 10p.p to make our model only trust the results beyong that margin, we have:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "errorMargin = 0.10\n",
    "ignored = 0\n",
    "truePos = 0\n",
    "trueNeg = 0\n",
    "falsePos = 0\n",
    "falseNeg = 0\n",
    "for index, row in dataTest.iterrows():\n",
    "    text = row['text']\n",
    "    headline= row['title']\n",
    "    numAuthors = len(row['authors'])\n",
    "    source = row['source']\n",
    "    party = \"\"\n",
    "    if 'party' in dataTest.columns:\n",
    "        party = row['party']\n",
    "    pred = isFakeNews(text, headline, numAuthors, source, party)\n",
    "\n",
    "    if (abs(0.5 - pred) < errorMargin):\n",
    "        ignored += 1\n",
    "    elif ((row['veracity'] == 1) &  (pred < 0.5) ):\n",
    "        truePos += 1\n",
    "    elif ((row['veracity'] == 0) & (pred >= 0.5) ):\n",
    "        trueNeg += 1\n",
    "    elif ((row['veracity'] == 1) &  (pred >= 0.5) ):\n",
    "        falsePos += 1            \n",
    "    elif ((row['veracity'] == 0) &  (pred < 0.5) ):\n",
    "        falseNeg += 1\n",
    "\n",
    "        \n",
    "print(\"truePos=\", truePos)\n",
    "print(\"trueNeg=\", trueNeg)\n",
    "print(\"falsePos=\", falsePos)\n",
    "print(\"falseNeg=\", falseNeg)\n",
    "print(\"ignored=\", ignored)\n",
    "print(\"accuracy=\", (truePos/(truePos+falseNeg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
